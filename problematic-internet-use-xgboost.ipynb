{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In the previous step, we have determined the best approach to imputing missing features. In this stage, we focus on improving the quality of our XGBoost model, trained on labelled data, in isolation. In parallel we may seek to optimise other models, such as DNN, and later aggregate these models.\n\n**Constants:**\n* Feature selection, preprocessing of tabular data\n* Missing feature imputation approach, as determined previously\n* Using labelled data only\n* Using XGBoost model only\n\n**Varying:**\n* Including or not including actigraph data\n* PCA on included features\n* Augmenting vs not augmenting data\n* XGBoost model parameters\n* Using sample weights based on number of features imputed\n* Evaluation function: negative mean squared error or QWK on binned target\n* Targeting PCIAT-PCIAT_Total, binned PCIAT or sii\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\n\nimport polars as pl\nfrom glob import glob\nfrom tqdm.auto import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport random\n\nnp.random.seed(42)\ntf.random.set_seed(42)\nrandom.seed(42)\n\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom sklearn.svm import SVR\n\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:00:40.071743Z","iopub.execute_input":"2025-01-20T05:00:40.072172Z","iopub.status.idle":"2025-01-20T05:01:05.702978Z","shell.execute_reply.started":"2025-01-20T05:00:40.072135Z","shell.execute_reply":"2025-01-20T05:01:05.701766Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Set up features and impute as determined previously","metadata":{}},{"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\ntest_data = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:01:05.704368Z","iopub.execute_input":"2025-01-20T05:01:05.705167Z","iopub.status.idle":"2025-01-20T05:01:05.801179Z","shell.execute_reply.started":"2025-01-20T05:01:05.705133Z","shell.execute_reply":"2025-01-20T05:01:05.800059Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/child-mind-institute-problematic-internet-use/\"\n\n# Import aggregate fields from parquet files\n# Modified code from rsakata: https://www.kaggle.com/code/rsakata/cmi-piu-16th-place-solution\n\nfiles_train = glob(INPUT_DIR + \"series_train.parquet/*\")\n#if IS_SUBMIT:\n#    files += glob(INPUT_DIR + \"series_test.parquet/*\")\n\nlist_df_train = []\nfor file in tqdm(files_train):\n    df_series = (\n        pl.read_parquet(file)\n        .with_columns(\n            (\n                (pl.col(\"relative_date_PCIAT\") - pl.col(\"relative_date_PCIAT\").min())*24\n                + (pl.col(\"time_of_day\") // int(1e9)) / 3600\n            ).floor().cast(int).alias(\"total_hours\")\n        )\n        .filter(pl.col(\"non-wear_flag\") != 1)\n        .filter(pl.col(\"step\").count().over(\"total_hours\") == 12 * 60)\n        .group_by(\"total_hours\").agg(\n            pl.col(\"enmo\").std().alias(\"enmo_std\"),\n            pl.col(\"anglez\").std().alias(\"anglez_std\"),\n            pl.col(\"light\").std().alias(\"light_std\")\n        )\n        .with_columns(\n            (pl.col(\"total_hours\") % 24).alias(\"hour\"),\n            pl.lit(file.split(\"/\")[-1][3:]).alias(\"id\")\n        )\n    )\n    list_df_train.append(df_series.to_pandas())\n\ndf_series = pd.concat(list_df_train)\ndf_series[\"enmo_std\"] = np.log(df_series[\"enmo_std\"] + 0.01)\ndf_series[\"anglez_std\"] = np.log(df_series[\"anglez_std\"] + 1)\ndf_series[\"light_std\"] = np.log(df_series[\"light_std\"] + 0.01)\n\ndf_agg_train = df_series.groupby(\"id\")[[\"enmo_std\", \"anglez_std\", \"light_std\"]].agg([\"mean\", \"std\"]).reset_index()\ndf_agg_train.columns = [cols[0] + \"_\" + cols[1] if cols[1] != \"\" else cols[0] for cols in df_agg_train.columns]\ndf_agg_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:07:40.475442Z","iopub.execute_input":"2025-01-20T05:07:40.475777Z","iopub.status.idle":"2025-01-20T05:08:52.123650Z","shell.execute_reply.started":"2025-01-20T05:07:40.475753Z","shell.execute_reply":"2025-01-20T05:08:52.122511Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/996 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39ce2df9ec3416597ea5bc38e391cc9"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"           id  enmo_std_mean  enmo_std_std  anglez_std_mean  anglez_std_std  \\\n0    00115b9f      -4.000377           NaN         1.989905             NaN   \n1    001f3379      -3.514671      0.652348         3.236993        0.678888   \n2    00f332d1      -3.071176      0.927238         3.249122        0.463244   \n3    01085eb3      -2.902040      0.791255         3.389762        0.315061   \n4    012cadd8      -2.806918      1.171675         3.337322        0.388409   \n..        ...            ...           ...              ...             ...   \n964  fe9c71d8      -3.116904      0.961804         3.037607        0.943554   \n965  fecc07d6      -3.969482      0.981531         1.332831        1.428363   \n966  ff18b749      -2.820076      0.937540         3.258458        0.417267   \n967  ffcd4dbd      -3.271800      0.827489         3.183395        0.629553   \n968  ffed1dd5      -3.359100      1.151259         2.489726        1.391600   \n\n     light_std_mean  light_std_std  \n0          0.051475            NaN  \n1          0.774591       2.945807  \n2          1.138379       2.939823  \n3          1.054698       2.185839  \n4          0.823770       3.350365  \n..              ...            ...  \n964       -0.394200       2.742634  \n965       -0.438018       1.795653  \n966        1.236652       3.341580  \n967        0.521227       2.665325  \n968       -1.597793       2.344771  \n\n[969 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>enmo_std_mean</th>\n      <th>enmo_std_std</th>\n      <th>anglez_std_mean</th>\n      <th>anglez_std_std</th>\n      <th>light_std_mean</th>\n      <th>light_std_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00115b9f</td>\n      <td>-4.000377</td>\n      <td>NaN</td>\n      <td>1.989905</td>\n      <td>NaN</td>\n      <td>0.051475</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001f3379</td>\n      <td>-3.514671</td>\n      <td>0.652348</td>\n      <td>3.236993</td>\n      <td>0.678888</td>\n      <td>0.774591</td>\n      <td>2.945807</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00f332d1</td>\n      <td>-3.071176</td>\n      <td>0.927238</td>\n      <td>3.249122</td>\n      <td>0.463244</td>\n      <td>1.138379</td>\n      <td>2.939823</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01085eb3</td>\n      <td>-2.902040</td>\n      <td>0.791255</td>\n      <td>3.389762</td>\n      <td>0.315061</td>\n      <td>1.054698</td>\n      <td>2.185839</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>012cadd8</td>\n      <td>-2.806918</td>\n      <td>1.171675</td>\n      <td>3.337322</td>\n      <td>0.388409</td>\n      <td>0.823770</td>\n      <td>3.350365</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>fe9c71d8</td>\n      <td>-3.116904</td>\n      <td>0.961804</td>\n      <td>3.037607</td>\n      <td>0.943554</td>\n      <td>-0.394200</td>\n      <td>2.742634</td>\n    </tr>\n    <tr>\n      <th>965</th>\n      <td>fecc07d6</td>\n      <td>-3.969482</td>\n      <td>0.981531</td>\n      <td>1.332831</td>\n      <td>1.428363</td>\n      <td>-0.438018</td>\n      <td>1.795653</td>\n    </tr>\n    <tr>\n      <th>966</th>\n      <td>ff18b749</td>\n      <td>-2.820076</td>\n      <td>0.937540</td>\n      <td>3.258458</td>\n      <td>0.417267</td>\n      <td>1.236652</td>\n      <td>3.341580</td>\n    </tr>\n    <tr>\n      <th>967</th>\n      <td>ffcd4dbd</td>\n      <td>-3.271800</td>\n      <td>0.827489</td>\n      <td>3.183395</td>\n      <td>0.629553</td>\n      <td>0.521227</td>\n      <td>2.665325</td>\n    </tr>\n    <tr>\n      <th>968</th>\n      <td>ffed1dd5</td>\n      <td>-3.359100</td>\n      <td>1.151259</td>\n      <td>2.489726</td>\n      <td>1.391600</td>\n      <td>-1.597793</td>\n      <td>2.344771</td>\n    </tr>\n  </tbody>\n</table>\n<p>969 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_data2 = train_data.merge(df_agg_train, how=\"left\", on=\"id\")\ntrain_data2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:35.280815Z","iopub.execute_input":"2025-01-20T05:09:35.281222Z","iopub.status.idle":"2025-01-20T05:09:35.325100Z","shell.execute_reply.started":"2025-01-20T05:09:35.281190Z","shell.execute_reply":"2025-01-20T05:09:35.324076Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n0  00008ff9                      Fall                5                0   \n1  000fd460                    Summer                9                0   \n2  00105258                    Summer               10                1   \n3  00115b9f                    Winter                9                0   \n4  0016bb22                    Spring               18                1   \n\n  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n0      Winter             51.0            Fall     16.877316             46.0   \n1         NaN              NaN            Fall     14.035590             48.0   \n2        Fall             71.0            Fall     16.648696             56.5   \n3        Fall             71.0          Summer     18.292347             56.0   \n4      Summer              NaN             NaN           NaN              NaN   \n\n   Physical-Weight  ...  SDS-SDS_Total_T  PreInt_EduHx-Season  \\\n0             50.8  ...              NaN                 Fall   \n1             46.0  ...             64.0               Summer   \n2             75.6  ...             54.0               Summer   \n3             81.6  ...             45.0               Winter   \n4              NaN  ...              NaN                  NaN   \n\n   PreInt_EduHx-computerinternet_hoursday  sii enmo_std_mean  enmo_std_std  \\\n0                                     3.0  2.0           NaN           NaN   \n1                                     0.0  0.0           NaN           NaN   \n2                                     2.0  0.0           NaN           NaN   \n3                                     0.0  1.0     -4.000377           NaN   \n4                                     NaN  NaN           NaN           NaN   \n\n   anglez_std_mean  anglez_std_std light_std_mean  light_std_std  \n0              NaN             NaN            NaN            NaN  \n1              NaN             NaN            NaN            NaN  \n2              NaN             NaN            NaN            NaN  \n3         1.989905             NaN       0.051475            NaN  \n4              NaN             NaN            NaN            NaN  \n\n[5 rows x 88 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Enroll_Season</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-Season</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Season</th>\n      <th>Physical-BMI</th>\n      <th>Physical-Height</th>\n      <th>Physical-Weight</th>\n      <th>...</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-Season</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>sii</th>\n      <th>enmo_std_mean</th>\n      <th>enmo_std_std</th>\n      <th>anglez_std_mean</th>\n      <th>anglez_std_std</th>\n      <th>light_std_mean</th>\n      <th>light_std_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>Fall</td>\n      <td>5</td>\n      <td>0</td>\n      <td>Winter</td>\n      <td>51.0</td>\n      <td>Fall</td>\n      <td>16.877316</td>\n      <td>46.0</td>\n      <td>50.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>Summer</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>14.035590</td>\n      <td>48.0</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>64.0</td>\n      <td>Summer</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>Summer</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Fall</td>\n      <td>16.648696</td>\n      <td>56.5</td>\n      <td>75.6</td>\n      <td>...</td>\n      <td>54.0</td>\n      <td>Summer</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>Winter</td>\n      <td>9</td>\n      <td>0</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Summer</td>\n      <td>18.292347</td>\n      <td>56.0</td>\n      <td>81.6</td>\n      <td>...</td>\n      <td>45.0</td>\n      <td>Winter</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-4.000377</td>\n      <td>NaN</td>\n      <td>1.989905</td>\n      <td>NaN</td>\n      <td>0.051475</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>Spring</td>\n      <td>18</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 88 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"files_test = glob(INPUT_DIR + \"series_test.parquet/*\")\n\n\nlist_df_test = []\nfor file in tqdm(files_test):\n    df_series = (\n        pl.read_parquet(file)\n        .with_columns(\n            (\n                (pl.col(\"relative_date_PCIAT\") - pl.col(\"relative_date_PCIAT\").min())*24\n                + (pl.col(\"time_of_day\") // int(1e9)) / 3600\n            ).floor().cast(int).alias(\"total_hours\")\n        )\n        .filter(pl.col(\"non-wear_flag\") != 1)\n        .filter(pl.col(\"step\").count().over(\"total_hours\") == 12 * 60)\n        .group_by(\"total_hours\").agg(\n            pl.col(\"enmo\").std().alias(\"enmo_std\"),\n            pl.col(\"anglez\").std().alias(\"anglez_std\"),\n            pl.col(\"light\").std().alias(\"light_std\")\n        )\n        .with_columns(\n            (pl.col(\"total_hours\") % 24).alias(\"hour\"),\n            pl.lit(file.split(\"/\")[-1][3:]).alias(\"id\")\n        )\n    )\n    list_df_test.append(df_series.to_pandas())\n\ndf_series = pd.concat(list_df_test)\ndf_series[\"enmo_std\"] = np.log(df_series[\"enmo_std\"] + 0.01)\ndf_series[\"anglez_std\"] = np.log(df_series[\"anglez_std\"] + 1)\ndf_series[\"light_std\"] = np.log(df_series[\"light_std\"] + 0.01)\n\ndf_agg_test = df_series.groupby(\"id\")[[\"enmo_std\", \"anglez_std\", \"light_std\"]].agg([\"mean\", \"std\"]).reset_index()\ndf_agg_test.columns = [cols[0] + \"_\" + cols[1] if cols[1] != \"\" else cols[0] for cols in df_agg_test.columns]\ndf_agg_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:39.398351Z","iopub.execute_input":"2025-01-20T05:09:39.398704Z","iopub.status.idle":"2025-01-20T05:09:39.576209Z","shell.execute_reply.started":"2025-01-20T05:09:39.398674Z","shell.execute_reply":"2025-01-20T05:09:39.574853Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41cdeebc51c4e4c9db9c9f12a625389"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         id  enmo_std_mean  enmo_std_std  anglez_std_mean  anglez_std_std  \\\n0  00115b9f      -4.000377           NaN         1.989905             NaN   \n1  001f3379      -3.514671      0.652348         3.236993        0.678888   \n\n   light_std_mean  light_std_std  \n0        0.051475            NaN  \n1        0.774591       2.945807  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>enmo_std_mean</th>\n      <th>enmo_std_std</th>\n      <th>anglez_std_mean</th>\n      <th>anglez_std_std</th>\n      <th>light_std_mean</th>\n      <th>light_std_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00115b9f</td>\n      <td>-4.000377</td>\n      <td>NaN</td>\n      <td>1.989905</td>\n      <td>NaN</td>\n      <td>0.051475</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001f3379</td>\n      <td>-3.514671</td>\n      <td>0.652348</td>\n      <td>3.236993</td>\n      <td>0.678888</td>\n      <td>0.774591</td>\n      <td>2.945807</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_data2 = test_data.merge(df_agg_test, how=\"left\", on=\"id\")\ntest_data2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:44.694339Z","iopub.execute_input":"2025-01-20T05:09:44.694674Z","iopub.status.idle":"2025-01-20T05:09:44.722855Z","shell.execute_reply.started":"2025-01-20T05:09:44.694651Z","shell.execute_reply":"2025-01-20T05:09:44.721579Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n0  00008ff9                      Fall                5                0   \n1  000fd460                    Summer                9                0   \n2  00105258                    Summer               10                1   \n3  00115b9f                    Winter                9                0   \n4  0016bb22                    Spring               18                1   \n\n  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n0      Winter             51.0            Fall     16.877316             46.0   \n1         NaN              NaN            Fall     14.035590             48.0   \n2        Fall             71.0            Fall     16.648696             56.5   \n3        Fall             71.0          Summer     18.292347             56.0   \n4      Summer              NaN             NaN           NaN              NaN   \n\n   Physical-Weight  ...  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n0             50.8  ...                NaN              NaN   \n1             46.0  ...               46.0             64.0   \n2             75.6  ...               38.0             54.0   \n3             81.6  ...               31.0             45.0   \n4              NaN  ...                NaN              NaN   \n\n   PreInt_EduHx-Season  PreInt_EduHx-computerinternet_hoursday enmo_std_mean  \\\n0                 Fall                                     3.0           NaN   \n1               Summer                                     0.0           NaN   \n2               Summer                                     2.0           NaN   \n3               Winter                                     0.0     -4.000377   \n4                  NaN                                     NaN           NaN   \n\n   enmo_std_std  anglez_std_mean  anglez_std_std light_std_mean  light_std_std  \n0           NaN              NaN             NaN            NaN            NaN  \n1           NaN              NaN             NaN            NaN            NaN  \n2           NaN              NaN             NaN            NaN            NaN  \n3           NaN         1.989905             NaN       0.051475            NaN  \n4           NaN              NaN             NaN            NaN            NaN  \n\n[5 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Enroll_Season</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-Season</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Season</th>\n      <th>Physical-BMI</th>\n      <th>Physical-Height</th>\n      <th>Physical-Weight</th>\n      <th>...</th>\n      <th>SDS-SDS_Total_Raw</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-Season</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>enmo_std_mean</th>\n      <th>enmo_std_std</th>\n      <th>anglez_std_mean</th>\n      <th>anglez_std_std</th>\n      <th>light_std_mean</th>\n      <th>light_std_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>Fall</td>\n      <td>5</td>\n      <td>0</td>\n      <td>Winter</td>\n      <td>51.0</td>\n      <td>Fall</td>\n      <td>16.877316</td>\n      <td>46.0</td>\n      <td>50.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>Summer</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>14.035590</td>\n      <td>48.0</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>46.0</td>\n      <td>64.0</td>\n      <td>Summer</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>Summer</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Fall</td>\n      <td>16.648696</td>\n      <td>56.5</td>\n      <td>75.6</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>54.0</td>\n      <td>Summer</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>Winter</td>\n      <td>9</td>\n      <td>0</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Summer</td>\n      <td>18.292347</td>\n      <td>56.0</td>\n      <td>81.6</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>45.0</td>\n      <td>Winter</td>\n      <td>0.0</td>\n      <td>-4.000377</td>\n      <td>NaN</td>\n      <td>1.989905</td>\n      <td>NaN</td>\n      <td>0.051475</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>Spring</td>\n      <td>18</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"X_train = train_data2[['Basic_Demos-Age',\n                      'Basic_Demos-Sex',\n                      'CGAS-CGAS_Score',\n                      'Physical-BMI',\n                      'BIA-BIA_BMI',\n                      'Physical-Waist_Circumference',\n                      'Physical-Diastolic_BP',\n                      'Physical-HeartRate',\n                      'Physical-Systolic_BP',\n                      'Fitness_Endurance-Max_Stage',\n                      'Fitness_Endurance-Time_Mins',\n                      'Fitness_Endurance-Time_Sec',\n                      'FGC-FGC_CU_Zone',\n                      'FGC-FGC_GSND_Zone',\n                      'FGC-FGC_GSD_Zone',\n                      'FGC-FGC_PU_Zone',\n                      'FGC-FGC_SRL_Zone',\n                      'FGC-FGC_SRR_Zone',\n                      'FGC-FGC_TL_Zone',\n                      'BIA-BIA_Activity_Level_num',\n                      'BIA-BIA_BMC',\n                      'BIA-BIA_BMR',\n                      'BIA-BIA_DEE',\n                      'BIA-BIA_ECW',\n                      'BIA-BIA_FFM',\n                      'BIA-BIA_FFMI',\n                      'BIA-BIA_FMI',\n                      'BIA-BIA_Fat',\n                      'BIA-BIA_ICW',\n                      'BIA-BIA_LDM',\n                      'BIA-BIA_LST',\n                      'BIA-BIA_SMM',\n                      'BIA-BIA_TBW',\n                      'PAQ_A-PAQ_A_Total',\n                      'PAQ_C-PAQ_C_Total',\n                      'SDS-SDS_Total_T',\n                      'PreInt_EduHx-computerinternet_hoursday'\n                       ,\n                      'enmo_std_mean',\n                      'enmo_std_std',\n                      'anglez_std_mean',\n                      'anglez_std_std',\n                      'light_std_mean',\n                      'light_std_std'\n                      ]]\n\ny_train = train_data2['PCIAT-PCIAT_Total']\n\nX_test = test_data2[['Basic_Demos-Age',\n                      'Basic_Demos-Sex',\n                      'CGAS-CGAS_Score',\n                      'Physical-BMI',\n                      'BIA-BIA_BMI',\n                      'Physical-Waist_Circumference',\n                      'Physical-Diastolic_BP',\n                      'Physical-HeartRate',\n                      'Physical-Systolic_BP',\n                      'Fitness_Endurance-Max_Stage',\n                      'Fitness_Endurance-Time_Mins',\n                      'Fitness_Endurance-Time_Sec',\n                      'FGC-FGC_CU_Zone',\n                      'FGC-FGC_GSND_Zone',\n                      'FGC-FGC_GSD_Zone',\n                      'FGC-FGC_PU_Zone',\n                      'FGC-FGC_SRL_Zone',\n                      'FGC-FGC_SRR_Zone',\n                      'FGC-FGC_TL_Zone',\n                      'BIA-BIA_Activity_Level_num',\n                      'BIA-BIA_BMC',\n                      'BIA-BIA_BMR',\n                      'BIA-BIA_DEE',\n                      'BIA-BIA_ECW',\n                      'BIA-BIA_FFM',\n                      'BIA-BIA_FFMI',\n                      'BIA-BIA_FMI',\n                      'BIA-BIA_Fat',\n                      'BIA-BIA_ICW',\n                      'BIA-BIA_LDM',\n                      'BIA-BIA_LST',\n                      'BIA-BIA_SMM',\n                      'BIA-BIA_TBW',\n                      'PAQ_A-PAQ_A_Total',\n                      'PAQ_C-PAQ_C_Total',\n                      'SDS-SDS_Total_T',\n                      'PreInt_EduHx-computerinternet_hoursday'\n                      ,\n                      'enmo_std_mean',\n                      'enmo_std_std',\n                      'anglez_std_mean',\n                      'anglez_std_std',\n                      'light_std_mean',\n                      'light_std_std'\n                   ]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:55.384606Z","iopub.execute_input":"2025-01-20T05:09:55.385010Z","iopub.status.idle":"2025-01-20T05:09:55.394785Z","shell.execute_reply.started":"2025-01-20T05:09:55.384943Z","shell.execute_reply":"2025-01-20T05:09:55.393796Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Add this only if we are not interested in the actigraph data\n\nX_train = X_train.drop(columns=['enmo_std_mean',\n                      'enmo_std_std',\n                      'anglez_std_mean',\n                      'anglez_std_std',\n                      'light_std_mean',\n                      'light_std_std'])\n\nX_test = X_test.drop(columns=['enmo_std_mean',\n                      'enmo_std_std',\n                      'anglez_std_mean',\n                      'anglez_std_std',\n                      'light_std_mean',\n                      'light_std_std'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:57.934371Z","iopub.execute_input":"2025-01-20T05:09:57.934703Z","iopub.status.idle":"2025-01-20T05:09:57.941932Z","shell.execute_reply.started":"2025-01-20T05:09:57.934678Z","shell.execute_reply":"2025-01-20T05:09:57.940930Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Add calculated fields\nX_train['Physical-BMI_Calc'] = X_train.apply(lambda row: row['Physical-BMI'] if row['Physical-BMI']==row['Physical-BMI'] else row['BIA-BIA_BMI'],axis=1)\nX_train['Fitness_Endurance-Time_Sec_Calc'] = X_train.apply(lambda row: row['Fitness_Endurance-Time_Sec'] + (row['Fitness_Endurance-Time_Mins']*60), axis=1)\nX_train['PAQ_Total'] = X_train.apply(lambda row: row['PAQ_A-PAQ_A_Total'] if row['PAQ_A-PAQ_A_Total']==row['PAQ_A-PAQ_A_Total'] else row['PAQ_C-PAQ_C_Total'],axis=1)\n\n\n# Drop fields no longer needed\nX_train = X_train.drop(columns=['PAQ_A-PAQ_A_Total','PAQ_C-PAQ_C_Total',\n                     'Physical-BMI','BIA-BIA_BMI',\n                     'Fitness_Endurance-Time_Mins','Fitness_Endurance-Time_Sec'])\n\n# Remove outliers - may give warnings due to NaN value comparison\nX_train.loc[X_train['CGAS-CGAS_Score']>=100.0,'CGAS-CGAS_Score'] = np.nan\nX_train.loc[X_train['Physical-Systolic_BP']>=180.0,'Physical-Systolic_BP'] = np.nan\nX_train.loc[X_train['Physical-Diastolic_BP']>=120.0,'Physical-Diastolic_BP'] = np.nan\nX_train.loc[X_train['BIA-BIA_DEE']>=6000.0,'BIA-BIA_DEE'] = np.nan\nX_train.loc[(X_train['BIA-BIA_BMC']<=0.0) | (X_train['BIA-BIA_BMC']>=16.0),'BIA-BIA_BMC'] = np.nan\nX_train.loc[(X_train['BIA-BIA_BMR']<=0.0) | (X_train['BIA-BIA_BMR']>=2400.0),'BIA-BIA_BMR'] = np.nan\nX_train.loc[(X_train['BIA-BIA_ECW']<=0.0) | (X_train['BIA-BIA_ECW']>=60.0),'BIA-BIA_ECW'] = np.nan\nX_train.loc[(X_train['BIA-BIA_FFM']<=0.0) | (X_train['BIA-BIA_FFM']>=200.0),'BIA-BIA_FFM'] = np.nan\nX_train.loc[(X_train['BIA-BIA_FFMI']<=0.0) | (X_train['BIA-BIA_FFMI']>=25.0),'BIA-BIA_FFMI'] = np.nan\nX_train.loc[(X_train['BIA-BIA_FMI']<=0.0) | (X_train['BIA-BIA_FMI']>=25.0),'BIA-BIA_FMI'] = np.nan\nX_train.loc[(X_train['BIA-BIA_Fat']<=8.0) | (X_train['BIA-BIA_Fat']>=60.0),'BIA-BIA_Fat'] = np.nan\nX_train.loc[(X_train['BIA-BIA_ICW']<=0.0) | (X_train['BIA-BIA_ICW']>=80.0),'BIA-BIA_ICW'] = np.nan\nX_train.loc[(X_train['BIA-BIA_LDM']<=0.0) | (X_train['BIA-BIA_LDM']>=60.0),'BIA-BIA_LDM'] = np.nan\nX_train.loc[(X_train['BIA-BIA_LST']<=0.0) | (X_train['BIA-BIA_LST']>=150.0),'BIA-BIA_LST'] = np.nan\nX_train.loc[(X_train['BIA-BIA_SMM']<=0.0) | (X_train['BIA-BIA_SMM']>=100.0),'BIA-BIA_SMM'] = np.nan\nX_train.loc[(X_train['BIA-BIA_TBW']<=0.0) | (X_train['BIA-BIA_TBW']>=150.0),'BIA-BIA_TBW'] = np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:01.029829Z","iopub.execute_input":"2025-01-20T05:10:01.030219Z","iopub.status.idle":"2025-01-20T05:10:01.195368Z","shell.execute_reply.started":"2025-01-20T05:10:01.030192Z","shell.execute_reply":"2025-01-20T05:10:01.194188Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"features_missing_labelled = X_train.loc[y_train.notna()].isnull().sum(axis=1)/X_train.shape[1]\nweights_labelled = 1 - features_missing_labelled\nweights_labelled.shape\n\nfeatures_missing_labelled2 = X_train.loc[y_train.notna()].isnull().sum(axis=1)\nweights_labelled2 = 1 * ((0.95)**features_missing_labelled2)\n\nweights_labelled3 = np.exp((-2)*features_missing_labelled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:04.018363Z","iopub.execute_input":"2025-01-20T05:10:04.018740Z","iopub.status.idle":"2025-01-20T05:10:04.037115Z","shell.execute_reply.started":"2025-01-20T05:10:04.018709Z","shell.execute_reply":"2025-01-20T05:10:04.035912Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#MICE\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\niter_imputer = IterativeImputer(max_iter=10, random_state=42)\nX_train_fimpute = pd.DataFrame(iter_imputer.fit_transform(X_train), columns = X_train.columns)\nX_train_fimpute.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:05.273391Z","iopub.execute_input":"2025-01-20T05:10:05.273750Z","iopub.status.idle":"2025-01-20T05:10:06.275741Z","shell.execute_reply.started":"2025-01-20T05:10:05.273720Z","shell.execute_reply":"2025-01-20T05:10:06.274781Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  \\\ncount      3960.000000      3960.000000      3960.000000   \nmean         10.433586         0.372727        64.818333   \nstd           3.574648         0.483591         9.805847   \nmin           5.000000         0.000000       -23.164848   \n25%           8.000000         0.000000        60.000000   \n50%          10.000000         0.000000        64.765647   \n75%          13.000000         1.000000        70.000000   \nmax          22.000000         1.000000        95.000000   \n\n       Physical-Waist_Circumference  Physical-Diastolic_BP  \\\ncount                   3960.000000            3960.000000   \nmean                      26.974426              69.403169   \nstd                        4.770198              11.011761   \nmin                        4.967968               0.000000   \n25%                       24.000000              64.000000   \n50%                       26.137767              69.000000   \n75%                       29.035486              73.000000   \nmax                       56.944995             119.000000   \n\n       Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  \\\ncount         3960.000000           3960.000000                  3960.000000   \nmean            81.519388            116.805724                     4.974030   \nstd             12.021297             14.228392                     0.935016   \nmin             27.000000              0.000000                     0.000000   \n25%             74.477905            109.000000                     4.865373   \n50%             81.485263            115.604541                     4.973003   \n75%             87.000000            122.000000                     5.081351   \nmax            138.000000            179.000000                    28.000000   \n\n       FGC-FGC_CU_Zone  FGC-FGC_GSND_Zone  ...  BIA-BIA_ICW  BIA-BIA_LDM  \\\ncount      3960.000000        3960.000000  ...  3960.000000  3960.000000   \nmean          0.480343           1.849340  ...    31.365620    18.066786   \nstd           0.389401           0.346190  ...     7.099089     5.021442   \nmin          -0.172314          -1.772461  ...    14.489000     4.635810   \n25%           0.000000           1.766934  ...    28.665877    16.394825   \n50%           0.485209           1.872826  ...    31.347850    18.058831   \n75%           1.000000           2.000000  ...    32.689980    18.232694   \nmax           1.129295           3.000000  ...    86.587576    52.527500   \n\n       BIA-BIA_LST  BIA-BIA_SMM  BIA-BIA_TBW  SDS-SDS_Total_T  \\\ncount  3960.000000  3960.000000  3960.000000      3960.000000   \nmean     63.749033    31.477562    50.138601        57.881433   \nstd      18.068723    10.250418    13.839926        10.737030   \nmin      23.620100     4.655730    20.589200        38.000000   \n25%      56.747700    27.190300    44.819225        51.000000   \n50%      63.734357    30.792761    50.135566        57.770114   \n75%      63.917531    33.007960    50.147145        60.000000   \nmax     188.145195   111.835760   146.075000       100.000000   \n\n       PreInt_EduHx-computerinternet_hoursday  Physical-BMI_Calc  \\\ncount                             3960.000000        3960.000000   \nmean                                 1.073783          19.374281   \nstd                                  1.022870           4.520383   \nmin                                 -0.278039           0.000000   \n25%                                  0.000000          16.485531   \n50%                                  1.000000          18.589876   \n75%                                  2.000000          21.015855   \nmax                                  3.019947          59.132048   \n\n       Fitness_Endurance-Time_Sec_Calc    PAQ_Total  \ncount                      3960.000000  3960.000000  \nmean                        468.721596     2.537644  \nstd                          89.856124     0.653839  \nmin                           5.000000     0.580000  \n25%                         450.588533     2.150000  \n50%                         469.207062     2.567600  \n75%                         487.416029     2.886524  \nmax                        2154.275208     4.790000  \n\n[8 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Waist_Circumference</th>\n      <th>Physical-Diastolic_BP</th>\n      <th>Physical-HeartRate</th>\n      <th>Physical-Systolic_BP</th>\n      <th>Fitness_Endurance-Max_Stage</th>\n      <th>FGC-FGC_CU_Zone</th>\n      <th>FGC-FGC_GSND_Zone</th>\n      <th>...</th>\n      <th>BIA-BIA_ICW</th>\n      <th>BIA-BIA_LDM</th>\n      <th>BIA-BIA_LST</th>\n      <th>BIA-BIA_SMM</th>\n      <th>BIA-BIA_TBW</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>Physical-BMI_Calc</th>\n      <th>Fitness_Endurance-Time_Sec_Calc</th>\n      <th>PAQ_Total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>...</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>10.433586</td>\n      <td>0.372727</td>\n      <td>64.818333</td>\n      <td>26.974426</td>\n      <td>69.403169</td>\n      <td>81.519388</td>\n      <td>116.805724</td>\n      <td>4.974030</td>\n      <td>0.480343</td>\n      <td>1.849340</td>\n      <td>...</td>\n      <td>31.365620</td>\n      <td>18.066786</td>\n      <td>63.749033</td>\n      <td>31.477562</td>\n      <td>50.138601</td>\n      <td>57.881433</td>\n      <td>1.073783</td>\n      <td>19.374281</td>\n      <td>468.721596</td>\n      <td>2.537644</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.574648</td>\n      <td>0.483591</td>\n      <td>9.805847</td>\n      <td>4.770198</td>\n      <td>11.011761</td>\n      <td>12.021297</td>\n      <td>14.228392</td>\n      <td>0.935016</td>\n      <td>0.389401</td>\n      <td>0.346190</td>\n      <td>...</td>\n      <td>7.099089</td>\n      <td>5.021442</td>\n      <td>18.068723</td>\n      <td>10.250418</td>\n      <td>13.839926</td>\n      <td>10.737030</td>\n      <td>1.022870</td>\n      <td>4.520383</td>\n      <td>89.856124</td>\n      <td>0.653839</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>-23.164848</td>\n      <td>4.967968</td>\n      <td>0.000000</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.172314</td>\n      <td>-1.772461</td>\n      <td>...</td>\n      <td>14.489000</td>\n      <td>4.635810</td>\n      <td>23.620100</td>\n      <td>4.655730</td>\n      <td>20.589200</td>\n      <td>38.000000</td>\n      <td>-0.278039</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>0.580000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.000000</td>\n      <td>0.000000</td>\n      <td>60.000000</td>\n      <td>24.000000</td>\n      <td>64.000000</td>\n      <td>74.477905</td>\n      <td>109.000000</td>\n      <td>4.865373</td>\n      <td>0.000000</td>\n      <td>1.766934</td>\n      <td>...</td>\n      <td>28.665877</td>\n      <td>16.394825</td>\n      <td>56.747700</td>\n      <td>27.190300</td>\n      <td>44.819225</td>\n      <td>51.000000</td>\n      <td>0.000000</td>\n      <td>16.485531</td>\n      <td>450.588533</td>\n      <td>2.150000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>64.765647</td>\n      <td>26.137767</td>\n      <td>69.000000</td>\n      <td>81.485263</td>\n      <td>115.604541</td>\n      <td>4.973003</td>\n      <td>0.485209</td>\n      <td>1.872826</td>\n      <td>...</td>\n      <td>31.347850</td>\n      <td>18.058831</td>\n      <td>63.734357</td>\n      <td>30.792761</td>\n      <td>50.135566</td>\n      <td>57.770114</td>\n      <td>1.000000</td>\n      <td>18.589876</td>\n      <td>469.207062</td>\n      <td>2.567600</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>13.000000</td>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>29.035486</td>\n      <td>73.000000</td>\n      <td>87.000000</td>\n      <td>122.000000</td>\n      <td>5.081351</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>32.689980</td>\n      <td>18.232694</td>\n      <td>63.917531</td>\n      <td>33.007960</td>\n      <td>50.147145</td>\n      <td>60.000000</td>\n      <td>2.000000</td>\n      <td>21.015855</td>\n      <td>487.416029</td>\n      <td>2.886524</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>22.000000</td>\n      <td>1.000000</td>\n      <td>95.000000</td>\n      <td>56.944995</td>\n      <td>119.000000</td>\n      <td>138.000000</td>\n      <td>179.000000</td>\n      <td>28.000000</td>\n      <td>1.129295</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>86.587576</td>\n      <td>52.527500</td>\n      <td>188.145195</td>\n      <td>111.835760</td>\n      <td>146.075000</td>\n      <td>100.000000</td>\n      <td>3.019947</td>\n      <td>59.132048</td>\n      <td>2154.275208</td>\n      <td>4.790000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 34 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Clip imputed values to original max and min\nfor column in X_train_fimpute.columns:\n    max_val = np.max(X_train[column])\n    min_val = np.min(X_train[column])\n    X_train_fimpute.loc[X_train_fimpute[column]>max_val,column] = max_val\n    X_train_fimpute.loc[X_train_fimpute[column]<min_val, column] = min_val\n\nX_train_fimpute.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:06.926889Z","iopub.execute_input":"2025-01-20T05:10:06.927262Z","iopub.status.idle":"2025-01-20T05:10:07.041403Z","shell.execute_reply.started":"2025-01-20T05:10:06.927234Z","shell.execute_reply":"2025-01-20T05:10:07.040296Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  \\\ncount      3960.000000      3960.000000      3960.000000   \nmean         10.433586         0.372727        64.830496   \nstd           3.574648         0.483591         9.726236   \nmin           5.000000         0.000000        25.000000   \n25%           8.000000         0.000000        60.000000   \n50%          10.000000         0.000000        64.765647   \n75%          13.000000         1.000000        70.000000   \nmax          22.000000         1.000000        95.000000   \n\n       Physical-Waist_Circumference  Physical-Diastolic_BP  \\\ncount                   3960.000000            3960.000000   \nmean                      26.998653              69.403169   \nstd                        4.692416              11.011761   \nmin                       18.000000               0.000000   \n25%                       24.000000              64.000000   \n50%                       26.137767              69.000000   \n75%                       29.035486              73.000000   \nmax                       50.000000             119.000000   \n\n       Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  \\\ncount         3960.000000           3960.000000                  3960.000000   \nmean            81.519388            116.805724                     4.974030   \nstd             12.021297             14.228392                     0.935016   \nmin             27.000000              0.000000                     0.000000   \n25%             74.477905            109.000000                     4.865373   \n50%             81.485263            115.604541                     4.973003   \n75%             87.000000            122.000000                     5.081351   \nmax            138.000000            179.000000                    28.000000   \n\n       FGC-FGC_CU_Zone  FGC-FGC_GSND_Zone  ...  BIA-BIA_ICW  BIA-BIA_LDM  \\\ncount      3960.000000        3960.000000  ...  3960.000000  3960.000000   \nmean          0.480419           1.850041  ...    31.363446    18.066786   \nstd           0.389164           0.341634  ...     7.083396     5.021442   \nmin           0.000000           1.000000  ...    14.489000     4.635810   \n25%           0.000000           1.766934  ...    28.665877    16.394825   \n50%           0.485209           1.872826  ...    31.347850    18.058831   \n75%           1.000000           2.000000  ...    32.689980    18.232694   \nmax           1.000000           3.000000  ...    79.473800    52.527500   \n\n       BIA-BIA_LST  BIA-BIA_SMM  BIA-BIA_TBW  SDS-SDS_Total_T  \\\ncount  3960.000000  3960.000000  3960.000000      3960.000000   \nmean     63.672368    31.469455    50.138601        57.881433   \nstd      17.644465    10.193244    13.839926        10.737030   \nmin      23.620100     4.655730    20.589200        38.000000   \n25%      56.747700    27.190300    44.819225        51.000000   \n50%      63.734357    30.792761    50.135566        57.770114   \n75%      63.917531    33.007960    50.147145        60.000000   \nmax     149.830000    97.923100   146.075000       100.000000   \n\n       PreInt_EduHx-computerinternet_hoursday  Physical-BMI_Calc  \\\ncount                             3960.000000        3960.000000   \nmean                                 1.073848          19.374281   \nstd                                  1.022777           4.520383   \nmin                                  0.000000           0.000000   \n25%                                  0.000000          16.485531   \n50%                                  1.000000          18.589876   \n75%                                  2.000000          21.015855   \nmax                                  3.000000          59.132048   \n\n       Fitness_Endurance-Time_Sec_Calc    PAQ_Total  \ncount                      3960.000000  3960.000000  \nmean                        468.480617     2.537644  \nstd                          86.553527     0.653839  \nmin                           5.000000     0.580000  \n25%                         450.588533     2.150000  \n50%                         469.207062     2.567600  \n75%                         487.416029     2.886524  \nmax                        1200.000000     4.790000  \n\n[8 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Waist_Circumference</th>\n      <th>Physical-Diastolic_BP</th>\n      <th>Physical-HeartRate</th>\n      <th>Physical-Systolic_BP</th>\n      <th>Fitness_Endurance-Max_Stage</th>\n      <th>FGC-FGC_CU_Zone</th>\n      <th>FGC-FGC_GSND_Zone</th>\n      <th>...</th>\n      <th>BIA-BIA_ICW</th>\n      <th>BIA-BIA_LDM</th>\n      <th>BIA-BIA_LST</th>\n      <th>BIA-BIA_SMM</th>\n      <th>BIA-BIA_TBW</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>Physical-BMI_Calc</th>\n      <th>Fitness_Endurance-Time_Sec_Calc</th>\n      <th>PAQ_Total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>...</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n      <td>3960.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>10.433586</td>\n      <td>0.372727</td>\n      <td>64.830496</td>\n      <td>26.998653</td>\n      <td>69.403169</td>\n      <td>81.519388</td>\n      <td>116.805724</td>\n      <td>4.974030</td>\n      <td>0.480419</td>\n      <td>1.850041</td>\n      <td>...</td>\n      <td>31.363446</td>\n      <td>18.066786</td>\n      <td>63.672368</td>\n      <td>31.469455</td>\n      <td>50.138601</td>\n      <td>57.881433</td>\n      <td>1.073848</td>\n      <td>19.374281</td>\n      <td>468.480617</td>\n      <td>2.537644</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.574648</td>\n      <td>0.483591</td>\n      <td>9.726236</td>\n      <td>4.692416</td>\n      <td>11.011761</td>\n      <td>12.021297</td>\n      <td>14.228392</td>\n      <td>0.935016</td>\n      <td>0.389164</td>\n      <td>0.341634</td>\n      <td>...</td>\n      <td>7.083396</td>\n      <td>5.021442</td>\n      <td>17.644465</td>\n      <td>10.193244</td>\n      <td>13.839926</td>\n      <td>10.737030</td>\n      <td>1.022777</td>\n      <td>4.520383</td>\n      <td>86.553527</td>\n      <td>0.653839</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>14.489000</td>\n      <td>4.635810</td>\n      <td>23.620100</td>\n      <td>4.655730</td>\n      <td>20.589200</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>0.580000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.000000</td>\n      <td>0.000000</td>\n      <td>60.000000</td>\n      <td>24.000000</td>\n      <td>64.000000</td>\n      <td>74.477905</td>\n      <td>109.000000</td>\n      <td>4.865373</td>\n      <td>0.000000</td>\n      <td>1.766934</td>\n      <td>...</td>\n      <td>28.665877</td>\n      <td>16.394825</td>\n      <td>56.747700</td>\n      <td>27.190300</td>\n      <td>44.819225</td>\n      <td>51.000000</td>\n      <td>0.000000</td>\n      <td>16.485531</td>\n      <td>450.588533</td>\n      <td>2.150000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>64.765647</td>\n      <td>26.137767</td>\n      <td>69.000000</td>\n      <td>81.485263</td>\n      <td>115.604541</td>\n      <td>4.973003</td>\n      <td>0.485209</td>\n      <td>1.872826</td>\n      <td>...</td>\n      <td>31.347850</td>\n      <td>18.058831</td>\n      <td>63.734357</td>\n      <td>30.792761</td>\n      <td>50.135566</td>\n      <td>57.770114</td>\n      <td>1.000000</td>\n      <td>18.589876</td>\n      <td>469.207062</td>\n      <td>2.567600</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>13.000000</td>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>29.035486</td>\n      <td>73.000000</td>\n      <td>87.000000</td>\n      <td>122.000000</td>\n      <td>5.081351</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>32.689980</td>\n      <td>18.232694</td>\n      <td>63.917531</td>\n      <td>33.007960</td>\n      <td>50.147145</td>\n      <td>60.000000</td>\n      <td>2.000000</td>\n      <td>21.015855</td>\n      <td>487.416029</td>\n      <td>2.886524</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>22.000000</td>\n      <td>1.000000</td>\n      <td>95.000000</td>\n      <td>50.000000</td>\n      <td>119.000000</td>\n      <td>138.000000</td>\n      <td>179.000000</td>\n      <td>28.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>79.473800</td>\n      <td>52.527500</td>\n      <td>149.830000</td>\n      <td>97.923100</td>\n      <td>146.075000</td>\n      <td>100.000000</td>\n      <td>3.000000</td>\n      <td>59.132048</td>\n      <td>1200.000000</td>\n      <td>4.790000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 34 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"scaler = StandardScaler()                  \n\nX_train_fimpute[X_train_fimpute.columns] = scaler.fit_transform(X_train_fimpute[X_train_fimpute.columns])\nX_train_fimpute.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:08.832442Z","iopub.execute_input":"2025-01-20T05:10:08.832795Z","iopub.status.idle":"2025-01-20T05:10:08.946617Z","shell.execute_reply.started":"2025-01-20T05:10:08.832767Z","shell.execute_reply":"2025-01-20T05:10:08.945526Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  \\\ncount     3.960000e+03     3.960000e+03     3.960000e+03   \nmean     -1.928872e-16    -5.831474e-17     8.343494e-16   \nstd       1.000126e+00     1.000126e+00     1.000126e+00   \nmin      -1.520226e+00    -7.708456e-01    -4.095678e+00   \n25%      -6.808763e-01    -7.708456e-01    -4.967087e-01   \n50%      -1.213100e-01    -7.708456e-01    -6.668295e-03   \n75%       7.180394e-01     1.297277e+00     5.315681e-01   \nmax       3.236088e+00     1.297277e+00     3.102260e+00   \n\n       Physical-Waist_Circumference  Physical-Diastolic_BP  \\\ncount                  3.960000e+03           3.960000e+03   \nmean                   5.921189e-17           2.866394e-16   \nstd                    1.000126e+00           1.000126e+00   \nmin                   -1.917944e+00          -6.303437e+00   \n25%                   -6.391231e-01          -4.907346e-01   \n50%                   -1.834866e-01          -3.661725e-02   \n75%                    4.341239e-01           3.266766e-01   \nmax                    4.902432e+00           4.504556e+00   \n\n       Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  \\\ncount        3.960000e+03          3.960000e+03                 3.960000e+03   \nmean         4.893953e-16         -3.545985e-16                 6.948426e-16   \nstd          1.000126e+00          1.000126e+00                 1.000126e+00   \nmin         -4.535806e+00         -8.210378e+00                -5.320400e+00   \n25%         -5.858247e-01         -5.486713e-01                -1.162227e-01   \n50%         -2.839099e-03         -8.443218e-02                -1.098129e-03   \n75%          4.559661e-01          3.651103e-01                 1.147947e-01   \nmax          4.698973e+00          4.371691e+00                 2.462940e+01   \n\n       FGC-FGC_CU_Zone  FGC-FGC_GSND_Zone  ...   BIA-BIA_ICW   BIA-BIA_LDM  \\\ncount     3.960000e+03       3.960000e+03  ...  3.960000e+03  3.960000e+03   \nmean     -1.282924e-16       1.058637e-16  ... -3.184882e-16 -1.004808e-16   \nstd       1.000126e+00       1.000126e+00  ...  1.000126e+00  1.000126e+00   \nmin      -1.234646e+00      -2.488480e+00  ... -2.382555e+00 -2.675063e+00   \n25%      -1.234646e+00      -2.432958e-01  ... -3.808780e-01 -3.330064e-01   \n50%       1.230976e-02       6.670247e-02  ... -2.202046e-03 -1.584385e-03   \n75%       1.335289e+00       4.390017e-01  ...  1.872974e-01  3.304415e-02   \nmax       1.335289e+00       3.366483e+00  ...  6.792848e+00  6.863580e+00   \n\n        BIA-BIA_LST   BIA-BIA_SMM   BIA-BIA_TBW  SDS-SDS_Total_T  \\\ncount  3.960000e+03  3.960000e+03  3.960000e+03     3.960000e+03   \nmean   1.040694e-16 -4.135861e-16  1.964758e-16    -1.821214e-16   \nstd    1.000126e+00  1.000126e+00  1.000126e+00     1.000126e+00   \nmin   -2.270249e+00 -2.630871e+00 -2.135353e+00    -1.851904e+00   \n25%   -3.925051e-01 -4.198561e-01 -3.843986e-01    -6.409875e-01   \n50%    3.513687e-03 -6.639494e-02 -2.193295e-04    -1.036914e-02   \n75%    1.389639e-02  1.509529e-01  6.173593e-04     1.973390e-01   \nmax    4.883600e+00  6.520205e+00  6.932733e+00     3.923235e+00   \n\n       PreInt_EduHx-computerinternet_hoursday  Physical-BMI_Calc  \\\ncount                            3.960000e+03       3.960000e+03   \nmean                            -5.741759e-17       9.796877e-16   \nstd                              1.000126e+00       1.000126e+00   \nmin                             -1.050066e+00      -4.286523e+00   \n25%                             -1.050066e+00      -6.391307e-01   \n50%                             -7.221268e-02      -1.735482e-01   \n75%                              9.056408e-01       3.631950e-01   \nmax                              1.883494e+00       8.796331e+00   \n\n       Fitness_Endurance-Time_Sec_Calc     PAQ_Total  \ncount                     3.960000e+03  3.960000e+03  \nmean                      4.831152e-16 -1.578984e-16  \nstd                       1.000126e+00  1.000126e+00  \nmin                      -5.355520e+00 -2.994455e+00  \n25%                      -2.067431e-01 -5.929487e-01  \n50%                       8.394070e-03  4.582149e-02  \n75%                       2.187987e-01  5.336544e-01  \nmax                       8.452709e+00  3.445252e+00  \n\n[8 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Waist_Circumference</th>\n      <th>Physical-Diastolic_BP</th>\n      <th>Physical-HeartRate</th>\n      <th>Physical-Systolic_BP</th>\n      <th>Fitness_Endurance-Max_Stage</th>\n      <th>FGC-FGC_CU_Zone</th>\n      <th>FGC-FGC_GSND_Zone</th>\n      <th>...</th>\n      <th>BIA-BIA_ICW</th>\n      <th>BIA-BIA_LDM</th>\n      <th>BIA-BIA_LST</th>\n      <th>BIA-BIA_SMM</th>\n      <th>BIA-BIA_TBW</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>Physical-BMI_Calc</th>\n      <th>Fitness_Endurance-Time_Sec_Calc</th>\n      <th>PAQ_Total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>...</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n      <td>3.960000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-1.928872e-16</td>\n      <td>-5.831474e-17</td>\n      <td>8.343494e-16</td>\n      <td>5.921189e-17</td>\n      <td>2.866394e-16</td>\n      <td>4.893953e-16</td>\n      <td>-3.545985e-16</td>\n      <td>6.948426e-16</td>\n      <td>-1.282924e-16</td>\n      <td>1.058637e-16</td>\n      <td>...</td>\n      <td>-3.184882e-16</td>\n      <td>-1.004808e-16</td>\n      <td>1.040694e-16</td>\n      <td>-4.135861e-16</td>\n      <td>1.964758e-16</td>\n      <td>-1.821214e-16</td>\n      <td>-5.741759e-17</td>\n      <td>9.796877e-16</td>\n      <td>4.831152e-16</td>\n      <td>-1.578984e-16</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>...</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n      <td>1.000126e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.520226e+00</td>\n      <td>-7.708456e-01</td>\n      <td>-4.095678e+00</td>\n      <td>-1.917944e+00</td>\n      <td>-6.303437e+00</td>\n      <td>-4.535806e+00</td>\n      <td>-8.210378e+00</td>\n      <td>-5.320400e+00</td>\n      <td>-1.234646e+00</td>\n      <td>-2.488480e+00</td>\n      <td>...</td>\n      <td>-2.382555e+00</td>\n      <td>-2.675063e+00</td>\n      <td>-2.270249e+00</td>\n      <td>-2.630871e+00</td>\n      <td>-2.135353e+00</td>\n      <td>-1.851904e+00</td>\n      <td>-1.050066e+00</td>\n      <td>-4.286523e+00</td>\n      <td>-5.355520e+00</td>\n      <td>-2.994455e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-6.808763e-01</td>\n      <td>-7.708456e-01</td>\n      <td>-4.967087e-01</td>\n      <td>-6.391231e-01</td>\n      <td>-4.907346e-01</td>\n      <td>-5.858247e-01</td>\n      <td>-5.486713e-01</td>\n      <td>-1.162227e-01</td>\n      <td>-1.234646e+00</td>\n      <td>-2.432958e-01</td>\n      <td>...</td>\n      <td>-3.808780e-01</td>\n      <td>-3.330064e-01</td>\n      <td>-3.925051e-01</td>\n      <td>-4.198561e-01</td>\n      <td>-3.843986e-01</td>\n      <td>-6.409875e-01</td>\n      <td>-1.050066e+00</td>\n      <td>-6.391307e-01</td>\n      <td>-2.067431e-01</td>\n      <td>-5.929487e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-1.213100e-01</td>\n      <td>-7.708456e-01</td>\n      <td>-6.668295e-03</td>\n      <td>-1.834866e-01</td>\n      <td>-3.661725e-02</td>\n      <td>-2.839099e-03</td>\n      <td>-8.443218e-02</td>\n      <td>-1.098129e-03</td>\n      <td>1.230976e-02</td>\n      <td>6.670247e-02</td>\n      <td>...</td>\n      <td>-2.202046e-03</td>\n      <td>-1.584385e-03</td>\n      <td>3.513687e-03</td>\n      <td>-6.639494e-02</td>\n      <td>-2.193295e-04</td>\n      <td>-1.036914e-02</td>\n      <td>-7.221268e-02</td>\n      <td>-1.735482e-01</td>\n      <td>8.394070e-03</td>\n      <td>4.582149e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.180394e-01</td>\n      <td>1.297277e+00</td>\n      <td>5.315681e-01</td>\n      <td>4.341239e-01</td>\n      <td>3.266766e-01</td>\n      <td>4.559661e-01</td>\n      <td>3.651103e-01</td>\n      <td>1.147947e-01</td>\n      <td>1.335289e+00</td>\n      <td>4.390017e-01</td>\n      <td>...</td>\n      <td>1.872974e-01</td>\n      <td>3.304415e-02</td>\n      <td>1.389639e-02</td>\n      <td>1.509529e-01</td>\n      <td>6.173593e-04</td>\n      <td>1.973390e-01</td>\n      <td>9.056408e-01</td>\n      <td>3.631950e-01</td>\n      <td>2.187987e-01</td>\n      <td>5.336544e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.236088e+00</td>\n      <td>1.297277e+00</td>\n      <td>3.102260e+00</td>\n      <td>4.902432e+00</td>\n      <td>4.504556e+00</td>\n      <td>4.698973e+00</td>\n      <td>4.371691e+00</td>\n      <td>2.462940e+01</td>\n      <td>1.335289e+00</td>\n      <td>3.366483e+00</td>\n      <td>...</td>\n      <td>6.792848e+00</td>\n      <td>6.863580e+00</td>\n      <td>4.883600e+00</td>\n      <td>6.520205e+00</td>\n      <td>6.932733e+00</td>\n      <td>3.923235e+00</td>\n      <td>1.883494e+00</td>\n      <td>8.796331e+00</td>\n      <td>8.452709e+00</td>\n      <td>3.445252e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 34 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Repeat the above for X_test\n\n# Add calculated fields\nX_test['Physical-BMI_Calc'] = X_test.apply(lambda row: row['Physical-BMI'] if row['Physical-BMI']==row['Physical-BMI'] else row['BIA-BIA_BMI'],axis=1)\nX_test['Fitness_Endurance-Time_Sec_Calc'] = X_test.apply(lambda row: row['Fitness_Endurance-Time_Sec'] + (row['Fitness_Endurance-Time_Mins']*60), axis=1)\nX_test['PAQ_Total'] = X_test.apply(lambda row: row['PAQ_A-PAQ_A_Total'] if row['PAQ_A-PAQ_A_Total']==row['PAQ_A-PAQ_A_Total'] else row['PAQ_C-PAQ_C_Total'],axis=1)\n\n# Drop fields no longer needed\nX_test = X_test.drop(columns=['PAQ_A-PAQ_A_Total','PAQ_C-PAQ_C_Total',\n                     'Physical-BMI','BIA-BIA_BMI',\n                     'Fitness_Endurance-Time_Mins','Fitness_Endurance-Time_Sec'])\n\n# Remove outliers\nX_test.loc[X_test['CGAS-CGAS_Score']>=100.0,'CGAS-CGAS_Score'] = np.nan\nX_test.loc[X_test['Physical-Systolic_BP']>=180.0,'Physical-Systolic_BP'] = np.nan\nX_test.loc[X_test['Physical-Diastolic_BP']>=120.0,'Physical-Diastolic_BP'] = np.nan\nX_test.loc[X_test['BIA-BIA_DEE']>=6000.0,'BIA-BIA_DEE'] = np.nan\nX_test.loc[(X_test['BIA-BIA_BMC']<=0.0) | (X_test['BIA-BIA_BMC']>=16.0),'BIA-BIA_BMC'] = np.nan\nX_test.loc[(X_test['BIA-BIA_BMR']<=0.0) | (X_test['BIA-BIA_BMR']>=2400.0),'BIA-BIA_BMR'] = np.nan\nX_test.loc[(X_test['BIA-BIA_ECW']<=0.0) | (X_test['BIA-BIA_ECW']>=60.0),'BIA-BIA_ECW'] = np.nan\nX_test.loc[(X_test['BIA-BIA_FFM']<=0.0) | (X_test['BIA-BIA_FFM']>=200.0),'BIA-BIA_FFM'] = np.nan\nX_test.loc[(X_test['BIA-BIA_FFMI']<=0.0) | (X_test['BIA-BIA_FFMI']>=25.0),'BIA-BIA_FFMI'] = np.nan\nX_test.loc[(X_test['BIA-BIA_FMI']<=0.0) | (X_test['BIA-BIA_FMI']>=25.0),'BIA-BIA_FMI'] = np.nan\nX_test.loc[(X_test['BIA-BIA_Fat']<=8.0) | (X_test['BIA-BIA_Fat']>=60.0),'BIA-BIA_Fat'] = np.nan\nX_test.loc[(X_test['BIA-BIA_ICW']<=0.0) | (X_test['BIA-BIA_ICW']>=80.0),'BIA-BIA_ICW'] = np.nan\nX_test.loc[(X_test['BIA-BIA_LDM']<=0.0) | (X_test['BIA-BIA_LDM']>=60.0),'BIA-BIA_LDM'] = np.nan\nX_test.loc[(X_test['BIA-BIA_LST']<=0.0) | (X_test['BIA-BIA_LST']>=150.0),'BIA-BIA_LST'] = np.nan\nX_test.loc[(X_test['BIA-BIA_SMM']<=0.0) | (X_test['BIA-BIA_SMM']>=100.0),'BIA-BIA_SMM'] = np.nan\nX_test.loc[(X_test['BIA-BIA_TBW']<=0.0) | (X_test['BIA-BIA_TBW']>=150.0),'BIA-BIA_TBW'] = np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:10.972612Z","iopub.execute_input":"2025-01-20T05:10:10.973019Z","iopub.status.idle":"2025-01-20T05:10:11.009276Z","shell.execute_reply.started":"2025-01-20T05:10:10.972948Z","shell.execute_reply":"2025-01-20T05:10:11.006003Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n  return op(a, b)\n/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Imputation\nX_test_fimpute = pd.DataFrame(iter_imputer.transform(X_test), columns = X_test.columns)\n\n# Clipping\nfor column in X_test_fimpute.columns:\n    max_val = np.max(X_train[column])\n    min_val = np.min(X_train[column])\n    X_test_fimpute.loc[X_test_fimpute[column]>max_val,column] = max_val\n    X_test_fimpute.loc[X_test_fimpute[column]<min_val, column] = min_val\n\n# Scaling\nX_test_fimpute[X_test_fimpute.columns] = scaler.transform(X_test_fimpute[X_test_fimpute.columns])\n\nX_test_fimpute.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:15.269836Z","iopub.execute_input":"2025-01-20T05:10:15.270246Z","iopub.status.idle":"2025-01-20T05:10:15.432713Z","shell.execute_reply.started":"2025-01-20T05:10:15.270215Z","shell.execute_reply":"2025-01-20T05:10:15.431797Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  \\\ncount        20.000000        20.000000        20.000000   \nmean          0.088527         0.056403        -0.045878   \nstd           1.042416         1.039489         0.801382   \nmin          -1.520226        -0.770846        -1.524985   \n25%          -0.401093        -0.770846        -0.398350   \n50%          -0.121310        -0.770846         0.053470   \n75%           0.508202         1.297277         0.442934   \nmax           2.396738         1.297277         1.559845   \n\n       Physical-Waist_Circumference  Physical-Diastolic_BP  \\\ncount                     20.000000              20.000000   \nmean                       0.062078              -0.054532   \nstd                        0.834814               0.728397   \nmin                       -1.917944              -1.126499   \n25%                       -0.639123              -0.626970   \n50%                        0.186887               0.013374   \n75%                        0.601291               0.157655   \nmax                        1.827302               2.099974   \n\n       Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  \\\ncount           20.000000             20.000000                    20.000000   \nmean            -0.024661              0.096746                    -0.099940   \nstd              0.630397              1.095310                     0.609633   \nmin             -0.958369             -1.532744                    -1.982619   \n25%             -0.479991             -0.323267                    -0.117459   \n50%             -0.096654              0.013656                    -0.010525   \n75%              0.349697              0.359988                     0.109218   \nmax              1.287928              3.247037                     1.097415   \n\n       FGC-FGC_CU_Zone  FGC-FGC_GSND_Zone  ...  BIA-BIA_ICW  BIA-BIA_LDM  \\\ncount        20.000000          20.000000  ...    20.000000    20.000000   \nmean         -0.092855          -0.200220  ...    -0.201746    -0.212473   \nstd           1.064675           0.889571  ...     0.502229     0.550313   \nmin          -1.234646          -2.488480  ...    -1.458277    -1.826683   \n25%          -1.234646          -0.271331  ...    -0.353243    -0.152373   \n50%          -0.226210          -0.084494  ...    -0.172488    -0.012274   \n75%           1.335289           0.310673  ...     0.143634     0.007697   \nmax           1.335289           1.002942  ...     0.662725     0.564693   \n\n       BIA-BIA_LST  BIA-BIA_SMM  BIA-BIA_TBW  SDS-SDS_Total_T  \\\ncount    20.000000    20.000000    20.000000        20.000000   \nmean     -0.149911    -0.186412    -0.143597        -0.248715   \nstd       0.534173     0.543306     0.553989         0.532311   \nmin      -1.403148    -1.575630    -1.668095        -1.665609   \n25%      -0.072266    -0.321185    -0.053025        -0.384832   \n50%       0.001130    -0.057763    -0.000024        -0.036684   \n75%       0.007959     0.164499     0.000693         0.043558   \nmax       0.908379     0.466421     0.938555         0.569929   \n\n       PreInt_EduHx-computerinternet_hoursday  Physical-BMI_Calc  \\\ncount                               20.000000          20.000000   \nmean                                 0.397885           0.159731   \nstd                                  1.029493           0.885501   \nmin                                 -1.050066          -1.181175   \n25%                                 -0.316676          -0.484882   \n50%                                  0.905641           0.059206   \n75%                                  0.934083           0.438107   \nmax                                  1.883494           2.371861   \n\n       Fitness_Endurance-Time_Sec_Calc  PAQ_Total  \ncount                        20.000000  20.000000  \nmean                         -0.138408  -0.321770  \nstd                           0.532544   1.215554  \nmin                          -1.577034  -2.290829  \n25%                          -0.194965  -0.793832  \n50%                          -0.060168  -0.247980  \n75%                           0.054260   0.197347  \nmax                           1.253942   2.405110  \n\n[8 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Waist_Circumference</th>\n      <th>Physical-Diastolic_BP</th>\n      <th>Physical-HeartRate</th>\n      <th>Physical-Systolic_BP</th>\n      <th>Fitness_Endurance-Max_Stage</th>\n      <th>FGC-FGC_CU_Zone</th>\n      <th>FGC-FGC_GSND_Zone</th>\n      <th>...</th>\n      <th>BIA-BIA_ICW</th>\n      <th>BIA-BIA_LDM</th>\n      <th>BIA-BIA_LST</th>\n      <th>BIA-BIA_SMM</th>\n      <th>BIA-BIA_TBW</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>Physical-BMI_Calc</th>\n      <th>Fitness_Endurance-Time_Sec_Calc</th>\n      <th>PAQ_Total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>...</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.088527</td>\n      <td>0.056403</td>\n      <td>-0.045878</td>\n      <td>0.062078</td>\n      <td>-0.054532</td>\n      <td>-0.024661</td>\n      <td>0.096746</td>\n      <td>-0.099940</td>\n      <td>-0.092855</td>\n      <td>-0.200220</td>\n      <td>...</td>\n      <td>-0.201746</td>\n      <td>-0.212473</td>\n      <td>-0.149911</td>\n      <td>-0.186412</td>\n      <td>-0.143597</td>\n      <td>-0.248715</td>\n      <td>0.397885</td>\n      <td>0.159731</td>\n      <td>-0.138408</td>\n      <td>-0.321770</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.042416</td>\n      <td>1.039489</td>\n      <td>0.801382</td>\n      <td>0.834814</td>\n      <td>0.728397</td>\n      <td>0.630397</td>\n      <td>1.095310</td>\n      <td>0.609633</td>\n      <td>1.064675</td>\n      <td>0.889571</td>\n      <td>...</td>\n      <td>0.502229</td>\n      <td>0.550313</td>\n      <td>0.534173</td>\n      <td>0.543306</td>\n      <td>0.553989</td>\n      <td>0.532311</td>\n      <td>1.029493</td>\n      <td>0.885501</td>\n      <td>0.532544</td>\n      <td>1.215554</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.520226</td>\n      <td>-0.770846</td>\n      <td>-1.524985</td>\n      <td>-1.917944</td>\n      <td>-1.126499</td>\n      <td>-0.958369</td>\n      <td>-1.532744</td>\n      <td>-1.982619</td>\n      <td>-1.234646</td>\n      <td>-2.488480</td>\n      <td>...</td>\n      <td>-1.458277</td>\n      <td>-1.826683</td>\n      <td>-1.403148</td>\n      <td>-1.575630</td>\n      <td>-1.668095</td>\n      <td>-1.665609</td>\n      <td>-1.050066</td>\n      <td>-1.181175</td>\n      <td>-1.577034</td>\n      <td>-2.290829</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.401093</td>\n      <td>-0.770846</td>\n      <td>-0.398350</td>\n      <td>-0.639123</td>\n      <td>-0.626970</td>\n      <td>-0.479991</td>\n      <td>-0.323267</td>\n      <td>-0.117459</td>\n      <td>-1.234646</td>\n      <td>-0.271331</td>\n      <td>...</td>\n      <td>-0.353243</td>\n      <td>-0.152373</td>\n      <td>-0.072266</td>\n      <td>-0.321185</td>\n      <td>-0.053025</td>\n      <td>-0.384832</td>\n      <td>-0.316676</td>\n      <td>-0.484882</td>\n      <td>-0.194965</td>\n      <td>-0.793832</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.121310</td>\n      <td>-0.770846</td>\n      <td>0.053470</td>\n      <td>0.186887</td>\n      <td>0.013374</td>\n      <td>-0.096654</td>\n      <td>0.013656</td>\n      <td>-0.010525</td>\n      <td>-0.226210</td>\n      <td>-0.084494</td>\n      <td>...</td>\n      <td>-0.172488</td>\n      <td>-0.012274</td>\n      <td>0.001130</td>\n      <td>-0.057763</td>\n      <td>-0.000024</td>\n      <td>-0.036684</td>\n      <td>0.905641</td>\n      <td>0.059206</td>\n      <td>-0.060168</td>\n      <td>-0.247980</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.508202</td>\n      <td>1.297277</td>\n      <td>0.442934</td>\n      <td>0.601291</td>\n      <td>0.157655</td>\n      <td>0.349697</td>\n      <td>0.359988</td>\n      <td>0.109218</td>\n      <td>1.335289</td>\n      <td>0.310673</td>\n      <td>...</td>\n      <td>0.143634</td>\n      <td>0.007697</td>\n      <td>0.007959</td>\n      <td>0.164499</td>\n      <td>0.000693</td>\n      <td>0.043558</td>\n      <td>0.934083</td>\n      <td>0.438107</td>\n      <td>0.054260</td>\n      <td>0.197347</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.396738</td>\n      <td>1.297277</td>\n      <td>1.559845</td>\n      <td>1.827302</td>\n      <td>2.099974</td>\n      <td>1.287928</td>\n      <td>3.247037</td>\n      <td>1.097415</td>\n      <td>1.335289</td>\n      <td>1.002942</td>\n      <td>...</td>\n      <td>0.662725</td>\n      <td>0.564693</td>\n      <td>0.908379</td>\n      <td>0.466421</td>\n      <td>0.938555</td>\n      <td>0.569929</td>\n      <td>1.883494</td>\n      <td>2.371861</td>\n      <td>1.253942</td>\n      <td>2.405110</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 34 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Use labelled data only","metadata":{}},{"cell_type":"code","source":"X_train_labelled = X_train_fimpute.loc[y_train.notna()]\ny_train_labelled = y_train[y_train.notna()]\nprint(\"Size of labelled train data set is: \", (X_train_labelled.shape, y_train_labelled.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:21.048702Z","iopub.execute_input":"2025-01-20T05:10:21.049147Z","iopub.status.idle":"2025-01-20T05:10:21.058386Z","shell.execute_reply.started":"2025-01-20T05:10:21.049113Z","shell.execute_reply":"2025-01-20T05:10:21.057257Z"}},"outputs":[{"name":"stdout","text":"Size of labelled train data set is:  ((2736, 34), (2736,))\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Since we are not using the unlabelled data in this notebook, we can drop the indices\n# This will help us prevent any accidents when doing cross-validation when we split by index, don't have to think about loc vs iloc etc.\n\nX_train_labelled = X_train_labelled.reset_index(drop=True)\ny_train_labelled = y_train_labelled.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:16:47.097651Z","iopub.execute_input":"2025-01-20T05:16:47.098157Z","iopub.status.idle":"2025-01-20T05:16:47.106093Z","shell.execute_reply.started":"2025-01-20T05:16:47.098123Z","shell.execute_reply":"2025-01-20T05:16:47.104937Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"weights_labelled = weights_labelled.reset_index(drop=True)\nweights_labelled2 = weights_labelled2.reset_index(drop=True)\nweights_labelled3 = weights_labelled3.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:16:48.454143Z","iopub.execute_input":"2025-01-20T05:16:48.454474Z","iopub.status.idle":"2025-01-20T05:16:48.459577Z","shell.execute_reply.started":"2025-01-20T05:16:48.454444Z","shell.execute_reply":"2025-01-20T05:16:48.458505Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Experimentation - optimising model","metadata":{}},{"cell_type":"markdown","source":"We are trying to find the best combination of:\n* Parquet data inclusion: No, Yes\n* PCA: all, 95%, 90%\n* Augment data: None, 1x noisy, 2x noisy, 1x noisier, 2x noisier\n* Loss/Evaluation function: NMSE or QWK\n* Model parameters\n* Sample weight when fitting: None, Linear, Exponential\n\n**Approach**:\n1. Begin with basic parameters:\n    * No Parquet\n    * No PCA\n    * No Data Augmentation\n    * NMSE Loss\n    * No Sample Weight\n    * Basic model","metadata":{"execution":{"iopub.status.busy":"2025-01-17T06:52:51.654240Z","iopub.execute_input":"2025-01-17T06:52:51.655147Z","iopub.status.idle":"2025-01-17T06:52:51.665188Z","shell.execute_reply.started":"2025-01-17T06:52:51.655097Z","shell.execute_reply":"2025-01-17T06:52:51.663264Z"}}},{"cell_type":"markdown","source":"# Set up useful functions and data\n* Augmented data\n* QWK metric\n* QWK loss function\n* Weights","metadata":{}},{"cell_type":"markdown","source":"* **X data**: X_train_labelled, X_train_labelled_aug1a, X_train_labelled_aug1b, X_train_labelled_aug2a, X_train_labelled_aug2b\n* **y data**: y_train_labelled, y_train_labelled_bin, y_train_labelled_sii\n* **Weights**: weights_linear, weights_exp\n* **Metric**: QWK\n* **Objective**: combined_loss\n","metadata":{}},{"cell_type":"code","source":"# X datasets - X_train_labelled, X_train_labelled_aug1a, X_train_labelled_aug1b, X_train_labelled_aug2a, X_train_labelled_aug2b\n# aug1/aug2 - augment once or twice\n# a/b - 0.1 noise multiplier, 0.15 noise multiplier\n\n# Augmented data\n\n# Get standard deviations of each column in X and y\nstd_X = np.std(X_train_labelled, axis=0)\nstd_y = np.std(y_train_labelled, axis=0)\n\n# Create augmented datasets\n\nX_noise_multiplier=0.1\ny_noise_multiplier=0.1\n\n# Deliberately not doing this in a for loop because we will not augment more than twice\n# For ease of understanding the datasets being created\n# And we may choose to add different noisiness to each augmentation\nX_train_labelled_noisy = X_train_labelled + (X_noise_multiplier * np.random.normal(0, std_X, X_train_labelled.shape))\ny_train_labelled_noisy = y_train_labelled + (y_noise_multiplier * np.random.normal(0, std_y, y_train_labelled.shape))\n\nX_train_labelled_aug1a = pd.concat([X_train_labelled,X_train_labelled_noisy], ignore_index=True)\ny_train_labelled_aug1a = pd.concat([y_train_labelled,y_train_labelled_noisy], ignore_index=True)\nprint(X_train_labelled_aug1a.shape, y_train_labelled_aug1a.shape)\n\n#repeat\nX_train_labelled_noisy = X_train_labelled + (X_noise_multiplier * np.random.normal(0, std_X, X_train_labelled.shape))\ny_train_labelled_noisy = y_train_labelled + (y_noise_multiplier * np.random.normal(0, std_y, y_train_labelled.shape))\n\nX_train_labelled_aug2a = pd.concat([X_train_labelled_aug1a,X_train_labelled_noisy], ignore_index=True)\ny_train_labelled_aug2a = pd.concat([y_train_labelled_aug1a,y_train_labelled_noisy], ignore_index=True)\nprint(X_train_labelled_aug2a.shape, y_train_labelled_aug2a.shape)\n\n\n# Increased noise multiplier\nX_noise_multiplier=0.15\ny_noise_multiplier=0.15\n\nX_train_labelled_noisy = X_train_labelled + (X_noise_multiplier * np.random.normal(0, std_X, X_train_labelled.shape))\ny_train_labelled_noisy = y_train_labelled + (y_noise_multiplier * np.random.normal(0, std_y, y_train_labelled.shape))\n\nX_train_labelled_aug1b = pd.concat([X_train_labelled,X_train_labelled_noisy], ignore_index=True)\ny_train_labelled_aug1b = pd.concat([y_train_labelled,y_train_labelled_noisy], ignore_index=True)\nprint(X_train_labelled_aug1b.shape, y_train_labelled_aug1b.shape)\n\n#repeat\nX_train_labelled_noisy = X_train_labelled + (X_noise_multiplier * np.random.normal(0, std_X, X_train_labelled.shape))\ny_train_labelled_noisy = y_train_labelled + (y_noise_multiplier * np.random.normal(0, std_y, y_train_labelled.shape))\n\nX_train_labelled_aug2b = pd.concat([X_train_labelled_aug1b,X_train_labelled_noisy], ignore_index=True)\ny_train_labelled_aug2b = pd.concat([y_train_labelled_aug1b,y_train_labelled_noisy], ignore_index=True)\nprint(X_train_labelled_aug2b.shape, y_train_labelled_aug2b.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:17:08.770137Z","iopub.execute_input":"2025-01-20T05:17:08.770483Z","iopub.status.idle":"2025-01-20T05:17:08.820204Z","shell.execute_reply.started":"2025-01-20T05:17:08.770459Z","shell.execute_reply":"2025-01-20T05:17:08.819114Z"}},"outputs":[{"name":"stdout","text":"(5472, 34) (5472,)\n(8208, 34) (8208,)\n(5472, 34) (5472,)\n(8208, 34) (8208,)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# y data: y_train_labelled, y_train_labelled_bin, y_train_labelled_sii\n# For simplicity, just augment without added noise for bin and sii\n\ny_train_labelled_sii = y_train_labelled.copy()\ny_train_labelled_sii.name='sii'\ny_train_labelled_sii = y_train_labelled_sii.apply(lambda row: 0 if row<=30 else \n                             (1 if row<50 else (\n                                2 if row<80 else (3)\n                            )))\n\ny_train_labelled_sii_aug1 = pd.concat([y_train_labelled_sii, y_train_labelled_sii], ignore_index=True)\ny_train_labelled_sii_aug2 = pd.concat([y_train_labelled_sii_aug1, y_train_labelled_sii], ignore_index=True)\n\ny_train_labelled_bin = y_train_labelled.copy()\ny_train_labelled_bin.name='PCIAT_bin'\ny_train_labelled_bin = y_train_labelled_bin.apply(lambda row: 0 if row<=15 else \n                                                  (1 if row<=30 else \n                                                   (2 if row<=40 else \n                                                    (3 if row<50 else \n                                                     (4 if row<=65 else \n                                                      (5 if row<80 else \n                                                       (6 if row<=90 else \n                                                        (7)\n                                                       )\n                                                      )\n                                                     )\n                                                    )\n                                                   )\n                                                  )\n                                                 )\n\ny_train_labelled_bin_aug1 = pd.concat([y_train_labelled_bin, y_train_labelled_bin], ignore_index=True)\ny_train_labelled_bin_aug2 = pd.concat([y_train_labelled_bin_aug1, y_train_labelled_bin], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:17:14.133081Z","iopub.execute_input":"2025-01-20T05:17:14.133416Z","iopub.status.idle":"2025-01-20T05:17:14.144687Z","shell.execute_reply.started":"2025-01-20T05:17:14.133390Z","shell.execute_reply":"2025-01-20T05:17:14.143642Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"y_train_labelled.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:19:15.693188Z","iopub.execute_input":"2025-01-20T05:19:15.693510Z","iopub.status.idle":"2025-01-20T05:19:15.700940Z","shell.execute_reply.started":"2025-01-20T05:19:15.693485Z","shell.execute_reply":"2025-01-20T05:19:15.699762Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0    55.0\n1     0.0\n2    28.0\n3    44.0\n4    34.0\n5    20.0\n6    10.0\n7    31.0\n8    58.0\n9     0.0\nName: PCIAT-PCIAT_Total, dtype: float64"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"y_train_labelled_bin.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:19:36.597611Z","iopub.execute_input":"2025-01-20T05:19:36.598059Z","iopub.status.idle":"2025-01-20T05:19:36.605068Z","shell.execute_reply.started":"2025-01-20T05:19:36.598023Z","shell.execute_reply":"2025-01-20T05:19:36.604090Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0    4\n1    0\n2    1\n3    3\n4    2\n5    1\n6    0\n7    2\n8    4\n9    0\nName: PCIAT_bin, dtype: int64"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"y_train_labelled_bin.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:23:10.277630Z","iopub.execute_input":"2025-01-20T05:23:10.278091Z","iopub.status.idle":"2025-01-20T05:23:10.288379Z","shell.execute_reply.started":"2025-01-20T05:23:10.278054Z","shell.execute_reply":"2025-01-20T05:23:10.287247Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"count    2736.000000\nmean        1.591009\nstd         1.536317\nmin         0.000000\n25%         0.000000\n50%         1.000000\n75%         3.000000\nmax         7.000000\nName: PCIAT_bin, dtype: float64"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Weights. We already have defined weights_labelled, weights_labelled2, weights_labelled3\n# Just need to augment\n\nweights_labelled_aug1 = pd.concat([weights_labelled, weights_labelled], ignore_index=True)\nweights_labelled_aug2 = pd.concat([weights_labelled_aug1, weights_labelled], ignore_index=True)\nprint(weights_labelled_aug1.shape, weights_labelled_aug2.shape)\n\nweights_labelled2_aug1 = pd.concat([weights_labelled2, weights_labelled2], ignore_index=True)\nweights_labelled2_aug2 = pd.concat([weights_labelled2_aug1, weights_labelled2], ignore_index=True)\nprint(weights_labelled2_aug1.shape, weights_labelled2_aug2.shape)\n\nweights_labelled3_aug1 = pd.concat([weights_labelled3, weights_labelled3], ignore_index=True)\nweights_labelled3_aug2 = pd.concat([weights_labelled3_aug1, weights_labelled3], ignore_index=True)\nprint(weights_labelled3_aug1.shape, weights_labelled3_aug2.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:20:25.102070Z","iopub.execute_input":"2025-01-20T05:20:25.102405Z","iopub.status.idle":"2025-01-20T05:20:25.113117Z","shell.execute_reply.started":"2025-01-20T05:20:25.102381Z","shell.execute_reply":"2025-01-20T05:20:25.111915Z"}},"outputs":[{"name":"stdout","text":"(5472,) (8208,)\n(5472,) (8208,)\n(5472,) (8208,)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"'''\n# For each of the target approaches: PCIAT, PCIAT_bin and sii, \n# I need a QWK metric and a combined NMSE+QWK loss function\n\n# Some reference to https://medium.com/@nlztrk/quadratic-weighted-kappa-qwk-metric-and-how-to-optimize-it-062cc9121baa\n\nfrom sklearn.metrics import confusion_matrix\n\n# This is the qwk score when we are passing the full PCIAT-PCIAT_Total\n# It needs to bin the target first\n\n# Bin a target from 0-100 into ten classes\ndef bin_target(y_val, max_val=100, num_classes=10):\n    #if y_val==max_val:\n    #   y_val-=1 #Make 100 into 99 so it can be classed with the rest\n    return np.clip(y_val//(max_val//(num_classes)),a_min=0,a_max=num_classes-1)\n\ndef qwk_pciat(y_true, y_pred):\n    num_classes=10 \n    #return cohen_kappa_score(y_true.numpy(), y_pred.numpy(), weights='quadratic') \n    # didn't manage to get the above working, ended up writing the function manually\n    max_val=100\n    #y_true_bin = bin_target(y_true.numpy(),max_val,num_classes)\n    #y_pred_bin = bin_target(y_pred.numpy(),max_val,num_classes) # Not working because SymbolicTensorflow doesn't have .numpy() apparently - solved here: https://github.com/tensorflow/tensorflow/issues/27519 comment by kenyukobayashi\n\n    y_true_bin = bin_target(y_true,max_val,num_classes)\n    y_pred_bin = bin_target(y_pred,max_val,num_classes) #For XGBoost, it seems to be numpy arrays\n    \n    #y_true_bin = bin_target(tf.make_ndarray(y_true),num_classes)\n    #y_pred_bin = bin_target(tf.make_ndarray(y_pred),num_classes)\n\n    # Confusion matrix O\n    O = confusion_matrix(y_true_bin, y_pred_bin, labels=np.arange(num_classes))\n    O = O/O.sum()\n\n    # Calculate the weight matrix W\n    W = np.zeros((num_classes, num_classes))\n    for i in range(num_classes):\n        for j in range(num_classes):\n            W[i, j] = (i - j) ** 2 / (num_classes - 1) ** 2\n\n    E = np.outer(np.sum(O, axis=1), np.sum(O, axis=0))\n\n    num = np.sum(W * O)\n    denom = np.sum(W * E)\n    return (1 - (num/denom))\n\n# Custom loss that combines MSE and QWK\ndef combined_loss_pciat(y_true, y_pred):\n    #mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\n    mse_loss = np.mean(np.square(y_true - y_pred))\n    #qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\n    #qwk_loss = qwk_pciat(y_true, y_pred)\n    #qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\n    # Add a weighting factor\n    #return mse_loss\n    #return (mse_loss, 10 * qwk_loss)\n    return mse_loss - (50 * qwk_loss) + 100 # Subtract qwk loss as higher qwk is better. Multiplier needs to be chosen by trial and error. Added constant so loss is > 0\n    #return (-1)*qwk_loss # Didn't work (no gradients provided) - seems it needs to be combined with nmse\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:21:38.286488Z","iopub.execute_input":"2025-01-20T05:21:38.286891Z","iopub.status.idle":"2025-01-20T05:21:38.295418Z","shell.execute_reply.started":"2025-01-20T05:21:38.286856Z","shell.execute_reply":"2025-01-20T05:21:38.294169Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"'''\ndef qwk_bin(y_true_bin, y_pred_bin):\n    num_classes=8\n    \n    # Confusion matrix O\n    O = confusion_matrix(y_true_bin, y_pred_bin, labels=np.arange(num_classes))\n    O = O/O.sum()\n\n    # Calculate the weight matrix W\n    W = np.zeros((num_classes, num_classes))\n    for i in range(num_classes):\n        for j in range(num_classes):\n            W[i, j] = (i - j) ** 2 / (num_classes - 1) ** 2\n\n    E = np.outer(np.sum(O, axis=1), np.sum(O, axis=0))\n\n    num = np.sum(W * O)\n    denom = np.sum(W * E)\n    return (1 - (num/denom))\n\n# Custom loss that combines MSE and QWK\ndef combined_loss_bin(y_true, y_pred):\n    #mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\n    mse_loss = np.mean(np.square(y_true - y_pred))\n    #qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\n    qwk_loss = qwk_bin(y_true, y_pred)\n    #qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\n    # Add a weighting factor\n    #return mse_loss\n    #return (mse_loss, 0.5 * qwk_loss)\n    return mse_loss - (0.5 * qwk_loss) + 1 # Subtract qwk loss as higher qwk is better. Multiplier needs to be chosen by trial and error. Added constant so loss is > 0\n    #return (-1)*qwk_loss # Didn't work (no gradients provided) - seems it needs to be combined with nmse\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:18:28.687625Z","iopub.execute_input":"2025-01-20T05:18:28.688051Z","iopub.status.idle":"2025-01-20T05:18:28.695523Z","shell.execute_reply.started":"2025-01-20T05:18:28.688010Z","shell.execute_reply":"2025-01-20T05:18:28.694247Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"'''\ndef qwk_sii(y_true_bin, y_pred_bin):\n    num_classes=4\n    \n    # Confusion matrix O\n    O = confusion_matrix(y_true_bin, y_pred_bin, labels=np.arange(num_classes))\n    O = O/O.sum()\n\n    # Calculate the weight matrix W\n    W = np.zeros((num_classes, num_classes))\n    for i in range(num_classes):\n        for j in range(num_classes):\n            W[i, j] = (i - j) ** 2 / (num_classes - 1) ** 2\n\n    E = np.outer(np.sum(O, axis=1), np.sum(O, axis=0))\n\n    num = np.sum(W * O)\n    denom = np.sum(W * E)\n    return (1 - (num/denom))\n\n# Custom loss that combines MSE and QWK\ndef combined_loss_sii(y_true, y_pred):\n    #mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\n    mse_loss = np.mean(np.square(y_true - y_pred))\n    #qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\n    qwk_loss = qwk_sii(y_true, y_pred)\n    #qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\n    # Add a weighting factor\n    #return mse_loss\n    #return (mse_loss, 0.5 * qwk_loss)\n    return mse_loss - (0.5 * qwk_loss) + 1 # Subtract qwk loss as higher qwk is better. Multiplier needs to be chosen by trial and error. Added constant so loss is > 0\n    #return (-1)*qwk_loss # Didn't work (no gradients provided) - seems it needs to be combined with nmse\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:18:29.663733Z","iopub.execute_input":"2025-01-20T05:18:29.664149Z","iopub.status.idle":"2025-01-20T05:18:29.671609Z","shell.execute_reply.started":"2025-01-20T05:18:29.664116Z","shell.execute_reply":"2025-01-20T05:18:29.670337Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#a = np.array([1,1,3])\n#b = np.array([0,1,3])\n#print(combined_loss_sii(a,b))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:18:30.680375Z","iopub.execute_input":"2025-01-20T05:18:30.680716Z","iopub.status.idle":"2025-01-20T05:18:30.684984Z","shell.execute_reply.started":"2025-01-20T05:18:30.680692Z","shell.execute_reply":"2025-01-20T05:18:30.684079Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"'''\nfrom sklearn.metrics import cohen_kappa_score\n\n# QWK Calculation\ndef quadratic_weighted_kappa(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    # Discretize continuous predictions if needed (e.g., rounding)\n    y_pred = np.round(y_pred)\n    \n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T08:18:01.743012Z","iopub.execute_input":"2025-01-18T08:18:01.743375Z","iopub.status.idle":"2025-01-18T08:18:01.748760Z","shell.execute_reply.started":"2025-01-18T08:18:01.743341Z","shell.execute_reply":"2025-01-18T08:18:01.747748Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"\"\\nfrom sklearn.metrics import cohen_kappa_score\\n\\n# QWK Calculation\\ndef quadratic_weighted_kappa(y_true, y_pred):\\n    y_true = np.array(y_true)\\n    y_pred = np.array(y_pred)\\n    \\n    # Discretize continuous predictions if needed (e.g., rounding)\\n    y_pred = np.round(y_pred)\\n    \\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\\n\""},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"'''\n# Convert QWK to a TensorFlow-friendly metric\ndef qwk_metric(y_true, y_pred):\n    qwk_value = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)\n    return qwk_value\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T05:31:55.475762Z","iopub.execute_input":"2025-01-18T05:31:55.476079Z","iopub.status.idle":"2025-01-18T05:31:55.481046Z","shell.execute_reply.started":"2025-01-18T05:31:55.476059Z","shell.execute_reply":"2025-01-18T05:31:55.479882Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'\\n# Convert QWK to a TensorFlow-friendly metric\\ndef qwk_metric(y_true, y_pred):\\n    qwk_value = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)\\n    return qwk_value\\n'"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"'''\n# Custom loss that combines MSE and QWK\ndef combined_loss(y_true, y_pred):\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\n    qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\n    qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\n    # Add a weighting factor\n    return mse_loss - 0.5 * qwk_loss\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T04:52:34.551669Z","iopub.execute_input":"2025-01-18T04:52:34.551974Z","iopub.status.idle":"2025-01-18T04:52:34.556866Z","shell.execute_reply.started":"2025-01-18T04:52:34.551955Z","shell.execute_reply":"2025-01-18T04:52:34.556100Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\n# Custom loss that combines MSE and QWK\\ndef combined_loss(y_true, y_pred):\\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\\n    qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\\n    qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\\n    # Add a weighting factor\\n    return mse_loss - 0.5 * qwk_loss\\n'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"'''\ndef bin_target(y_val, max_val=100, num_classes=11):\n    #return y_val//(num_classes-1) #integer division for ordinal classes\n    return y_val//(max_val//(num_classes-1)) \n    #e.g., 100 split into 11 classes: 0-9, 10-19, ..., 90-99, 100\n    # 100 split into 6 classes: 0-19, 20-39, ..., 80-99, 100\n    # With 0-100 values doing integer division we have this extra 100 term in its own class - there's probably a better way of splitting\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T04:52:39.566343Z","iopub.execute_input":"2025-01-18T04:52:39.566664Z","iopub.status.idle":"2025-01-18T04:52:39.570730Z","shell.execute_reply.started":"2025-01-18T04:52:39.566642Z","shell.execute_reply":"2025-01-18T04:52:39.569773Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"'''\n# Some reference to https://medium.com/@nlztrk/quadratic-weighted-kappa-qwk-metric-and-how-to-optimize-it-062cc9121baa\n\nfrom sklearn.metrics import confusion_matrix\n\ndef qwk(y_true, y_pred):\n    num_classes=11 # Ranging from 0 to 10 (from (0 to 100) // 10). Slightly sketch since 10 is 1/10th as likely as any other class. The hope is that there aren't enough 100s to matter\n    #return cohen_kappa_score(y_true.numpy(), y_pred.numpy(), weights='quadratic') \n    # didn't manage to get the above working, ended up writing the function manually\n    max_val=100\n    #y_true_bin = bin_target(y_true.numpy(),max_val,num_classes)\n    #y_pred_bin = bin_target(y_pred.numpy(),max_val,num_classes) # Not working because SymbolicTensorflow doesn't have .numpy() apparently - solved here: https://github.com/tensorflow/tensorflow/issues/27519 comment by kenyukobayashi\n\n    y_true_bin = bin_target(y_true,max_val,num_classes)\n    y_pred_bin = bin_target(y_pred,max_val,num_classes) #For XGBoost, it seems to be numpy arrays\n    \n    #y_true_bin = bin_target(tf.make_ndarray(y_true),num_classes)\n    #y_pred_bin = bin_target(tf.make_ndarray(y_pred),num_classes)\n\n    # Confusion matrix O\n    O = confusion_matrix(y_true_bin, y_pred_bin, labels=np.arange(num_classes))\n    O = O/O.sum()\n\n    # Calculate the weight matrix W\n    W = np.zeros((num_classes, num_classes))\n    for i in range(num_classes):\n        for j in range(num_classes):\n            W[i, j] = (i - j) ** 2 / (num_classes - 1) ** 2\n\n    E = np.outer(np.sum(O, axis=1), np.sum(O, axis=0))\n\n    num = np.sum(W * O)\n    denom = np.sum(W * E)\n    return (1 - (num/denom)) \n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T04:52:50.518250Z","iopub.execute_input":"2025-01-18T04:52:50.518600Z","iopub.status.idle":"2025-01-18T04:52:50.524964Z","shell.execute_reply.started":"2025-01-18T04:52:50.518578Z","shell.execute_reply":"2025-01-18T04:52:50.523622Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Custom qwk metric and loss function for pciat_bin\n# Modified from https://medium.com/@nlztrk/quadratic-weighted-kappa-qwk-metric-and-how-to-optimize-it-062cc9121baa\ny = np.array([0,1,1,2,3,4,5,6,6,6,5,7,2,6,5,4,3])\n\na = 3.88\nb = 4.15\n\ng = np.zeros(8)\nfor i in range(8):\n    g[i] = ((y - i)**2).mean()\n    #g[i] = i\n\nprint(g)\nh = [(x-a)**2 + b for x in [0,1,2,3,4,5,6,7]]\nprint(h)\n\nplt.plot([0,1,2,3,4,5,6,7], g, marker=\".\", label=\"actual\")\nplt.plot([0,1,2,3,4,5,6,7], [(x-a)**2 + b for x in [0,1,2,3,4,5,6,7]], label=\"fitting\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:27:38.721116Z","iopub.execute_input":"2025-01-20T05:27:38.721476Z","iopub.status.idle":"2025-01-20T05:27:38.924659Z","shell.execute_reply.started":"2025-01-20T05:27:38.721447Z","shell.execute_reply":"2025-01-20T05:27:38.923455Z"}},"outputs":[{"name":"stdout","text":"[19.29411765 12.52941176  7.76470588  5.          4.23529412  5.47058824\n  8.70588235 13.94117647]\n[19.2044, 12.4444, 7.6844, 4.9244, 4.1644000000000005, 5.404400000000001, 8.644400000000001, 13.884400000000001]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\n# Metric\ndef quadratic_weighted_kappa_bin(y_true, y_pred):\n    if isinstance(y_pred, xgb.QuantileDMatrix):\n        # XGB\n        y_true, y_pred = y_pred, y_true\n\n        y_true = (y_true.get_label() + a).round()\n        y_pred = (y_pred + a).clip(0, 7).round()\n        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n        return 'QWK', qwk\n\n    else:\n        # For LightGBM\n        y_true = y_true + a\n        y_pred = (y_pred + a).clip(0, 7).round()\n        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n        return 'QWK', qwk, True\n\n# Metric for both XGB and LGB\ndef qwk_obj_bin(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(0, 7)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:28:13.641493Z","iopub.execute_input":"2025-01-20T05:28:13.641874Z","iopub.status.idle":"2025-01-20T05:28:13.649539Z","shell.execute_reply.started":"2025-01-20T05:28:13.641839Z","shell.execute_reply":"2025-01-20T05:28:13.648397Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Custom qwk metric and loss function for pciat_sii\n#Modified from https://medium.com/@nlztrk/quadratic-weighted-kappa-qwk-metric-and-how-to-optimize-it-062cc9121baa\ny = np.array([0,1,2,1,1,2,3,3,2,3,2,1,2,1,0,1,0])\n\nc = 1.47\nd = 0.95\n\ng = np.zeros(4)\nfor i in range(4):\n    g[i] = ((y - i)**2).mean()\n    #g[i] = i\n\nprint(g)\nh = [(x-c)**2 + d for x in [0,1,2,3]]\nprint(h)\n\nplt.plot([0,1,2,3], g, marker=\".\", label=\"actual\")\nplt.plot([0,1,2,3], [(x-c)**2 + d for x in [0,1,2,3]], label=\"fitting\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:28:29.647130Z","iopub.execute_input":"2025-01-20T05:28:29.647457Z","iopub.status.idle":"2025-01-20T05:28:29.836327Z","shell.execute_reply.started":"2025-01-20T05:28:29.647432Z","shell.execute_reply":"2025-01-20T05:28:29.835311Z"}},"outputs":[{"name":"stdout","text":"[3.11764706 1.17647059 1.23529412 3.29411765]\n[3.1109, 1.1709, 1.2309, 3.2908999999999997]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"# Metric\ndef quadratic_weighted_kappa_sii(y_true, y_pred):\n    if isinstance(y_pred, xgb.QuantileDMatrix):\n        # XGB\n        y_true, y_pred = y_pred, y_true\n\n        y_true = (y_true.get_label() + c).round()\n        y_pred = (y_pred + c).clip(0, 3).round()\n        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n        return 'QWK', qwk\n\n    else:\n        # For LightGBM\n        y_true = y_true + c\n        y_pred = (y_pred + c).clip(0, 3).round()\n        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n        return 'QWK', qwk, True\n\n# Metric for both XGB and LGB\ndef qwk_obj_sii(y_true, y_pred):\n    labels = y_true + c\n    preds = y_pred + c\n    preds = preds.clip(0, 3)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-c)**2+d)\n    df = preds - labels\n    dg = preds - c\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:28:41.956302Z","iopub.execute_input":"2025-01-20T05:28:41.956638Z","iopub.status.idle":"2025-01-20T05:28:41.964414Z","shell.execute_reply.started":"2025-01-20T05:28:41.956611Z","shell.execute_reply":"2025-01-20T05:28:41.962858Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"'''\n# Custom loss that combines MSE and QWK\ndef combined_loss(y_true, y_pred):\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\n    #qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\n    qwk_loss = qwk(y_true, y_pred)\n    #qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\n    # Add a weighting factor\n    #return mse_loss\n    #return (mse_loss, 10 * qwk_loss)\n    return mse_loss - (50 * qwk_loss) + 100 # Subtract qwk loss as higher qwk is better. Multiplier needs to be chosen by trial and error. Added constant so loss is > 0\n    #return (-1)*qwk_loss # Didn't work (no gradients provided) - seems it needs to be combined with nmse\n'''\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:28:49.021178Z","iopub.execute_input":"2025-01-20T05:28:49.021542Z","iopub.status.idle":"2025-01-20T05:28:49.027699Z","shell.execute_reply.started":"2025-01-20T05:28:49.021516Z","shell.execute_reply":"2025-01-20T05:28:49.026868Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"\"\\n# Custom loss that combines MSE and QWK\\ndef combined_loss(y_true, y_pred):\\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))  # Mean Squared Error\\n    #qwk_loss = tf.py_function(quadratic_weighted_kappa, [y_true, y_pred], tf.float64)  # QWK\\n    qwk_loss = qwk(y_true, y_pred)\\n    #qwk_loss = tf.convert_to_tensor(qwk_loss, dtype=tf.float32)\\n    # Add a weighting factor\\n    #return mse_loss\\n    #return (mse_loss, 10 * qwk_loss)\\n    return mse_loss - (50 * qwk_loss) + 100 # Subtract qwk loss as higher qwk is better. Multiplier needs to be chosen by trial and error. Added constant so loss is > 0\\n    #return (-1)*qwk_loss # Didn't work (no gradients provided) - seems it needs to be combined with nmse\\n\""},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"1. First, we look for good combos of actigraph inclusion, PCA, augmentation and sample weights\n2. Then, we keep those combos and look for different targets and objective functions\n3. Finally, we vary XGBoost model parameters\n","metadata":{}},{"cell_type":"markdown","source":"# V1: Basic model","metadata":{}},{"cell_type":"code","source":"#xgb_model = XGBRegressor(random_state=42, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T06:58:10.276074Z","iopub.execute_input":"2025-01-17T06:58:10.276492Z","iopub.status.idle":"2025-01-17T06:58:10.283817Z","shell.execute_reply.started":"2025-01-17T06:58:10.276456Z","shell.execute_reply":"2025-01-17T06:58:10.282639Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#xgb_model.fit(X_train_labelled, y_train_labelled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T06:58:37.687062Z","iopub.execute_input":"2025-01-17T06:58:37.687388Z","iopub.status.idle":"2025-01-17T06:58:37.956572Z","shell.execute_reply.started":"2025-01-17T06:58:37.687364Z","shell.execute_reply":"2025-01-17T06:58:37.955591Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"**Score: 0.388, 0.377**","metadata":{}},{"cell_type":"markdown","source":"# V2: Using augmented data","metadata":{}},{"cell_type":"code","source":"'''\nxgb_param_grid = {\n    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate\n    'max_depth': [3, 5, 7, 9],  # Depth of each tree\n    'min_child_weight': [1, 3, 5],  # Minimum sum of instance weight for a node to be a leaf\n    'subsample': [0.7, 0.8, 0.9, 1.0]  # Fraction of training data used for each tree\n}\n\nmodel = XGBRegressor(objective='reg:squarederror', random_state=42)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=xgb_param_grid, \n                           scoring='neg_mean_squared_error',  # For regression tasks, use MSE or RMSE\n                           cv=5,  # 5-fold cross-validation\n                           verbose=1,  # Show progress\n                           n_jobs=-1,  # Use all CPU cores\n                           refit=True)  # Refit the model with the best parameters\n\ngrid_search.fit(X_train_labelled_aug1, y_train_labelled_aug1)\n\n# Print best parameters and best score for XGBoost\nprint(\"Best parameters for XGBoost:\", grid_search.best_params_)\nprint(\"Best CV score for XGBoost:\", grid_search.best_score_)\n\n#Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 300, 'subsample': 0.9}\n#Best CV score for XGBoost: -129.1881143988609\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T11:23:46.561734Z","iopub.execute_input":"2025-01-17T11:23:46.562117Z","iopub.status.idle":"2025-01-17T12:09:56.026800Z","shell.execute_reply.started":"2025-01-17T11:23:46.562083Z","shell.execute_reply":"2025-01-17T12:09:56.025665Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 432 candidates, totalling 2160 fits\nBest parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 300, 'subsample': 0.9}\nBest CV score for XGBoost: -129.1881143988609\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"#xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror', learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=300, subsample=0.9)\n#xgb_model = XGBRegressor(random_state=42, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T08:18:34.104623Z","iopub.execute_input":"2025-01-18T08:18:34.104977Z","iopub.status.idle":"2025-01-18T08:18:34.109126Z","shell.execute_reply.started":"2025-01-18T08:18:34.104951Z","shell.execute_reply":"2025-01-18T08:18:34.108111Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"#xgb_model.fit(X_train_labelled_aug2b, y_train_labelled_aug2b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T08:18:39.234099Z","iopub.execute_input":"2025-01-18T08:18:39.234430Z","iopub.status.idle":"2025-01-18T08:18:39.419495Z","shell.execute_reply.started":"2025-01-18T08:18:39.234400Z","shell.execute_reply":"2025-01-18T08:18:39.417560Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"# V3: PCA","metadata":{}},{"cell_type":"code","source":"#pca = PCA(n_components=34)\n#X_train_labelled_pca = pd.DataFrame(pca.fit_transform(X_train_labelled))\n#X_test_fimpute_pca = pd.DataFrame(pca.transform(X_test_fimpute))\n\n#X_train_labelled_pca.shape, X_test_fimpute_pca.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:32:41.126059Z","iopub.execute_input":"2025-01-18T10:32:41.126410Z","iopub.status.idle":"2025-01-18T10:32:41.144992Z","shell.execute_reply.started":"2025-01-18T10:32:41.126383Z","shell.execute_reply":"2025-01-18T10:32:41.143790Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"((2736, 34), (20, 34))"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"#xgb_model = XGBRegressor(random_state=42, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T09:45:57.850440Z","iopub.execute_input":"2025-01-18T09:45:57.850837Z","iopub.status.idle":"2025-01-18T09:45:57.854943Z","shell.execute_reply.started":"2025-01-18T09:45:57.850808Z","shell.execute_reply":"2025-01-18T09:45:57.853931Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"#xgb_model.fit(X_train_labelled_pca, y_train_labelled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T09:57:54.548685Z","iopub.execute_input":"2025-01-18T09:57:54.549020Z","iopub.status.idle":"2025-01-18T09:57:54.719271Z","shell.execute_reply.started":"2025-01-18T09:57:54.548995Z","shell.execute_reply":"2025-01-18T09:57:54.718360Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":98},{"cell_type":"markdown","source":"PCA didn't really seem to help in any situation - we are probably underfitting to begin with.","metadata":{}},{"cell_type":"markdown","source":"# V4: Sample weights","metadata":{}},{"cell_type":"markdown","source":"We are not going to be using PCA. We can test augmentation with 1b and 2b (and 1a and 2a, though they have been consistently worse). We have not yet dismissed including the actigraph data but we will start by not including it.","metadata":{}},{"cell_type":"code","source":"#xgb_model = XGBRegressor(random_state=42, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T11:46:19.985903Z","iopub.execute_input":"2025-01-18T11:46:19.986292Z","iopub.status.idle":"2025-01-18T11:46:19.990743Z","shell.execute_reply.started":"2025-01-18T11:46:19.986230Z","shell.execute_reply":"2025-01-18T11:46:19.989700Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"#xgb_model.fit(X_train_labelled_aug2a, y_train_labelled_aug2a, sample_weight=weights_labelled3_aug2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T11:46:34.916132Z","iopub.execute_input":"2025-01-18T11:46:34.916541Z","iopub.status.idle":"2025-01-18T11:46:35.140029Z","shell.execute_reply.started":"2025-01-18T11:46:34.916488Z","shell.execute_reply":"2025-01-18T11:46:35.138986Z"}},"outputs":[{"execution_count":179,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":179},{"cell_type":"markdown","source":"Mixed results. Linear weights were not bad for non-augmented data, and geometric weights for once-augmented data. But cannot say that any sample weight approach was an improvement on the base.","metadata":{}},{"cell_type":"markdown","source":"# V5: Different target data","metadata":{}},{"cell_type":"markdown","source":"Trying target bin and target sii, as well as different objective functions","metadata":{}},{"cell_type":"code","source":"#xgb_model = XGBRegressor(random_state=42, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)\n#xgb_model = XGBRegressor(random_state=42, objective=qwk_obj_bin, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)\nxgb_model = XGBRegressor(random_state=42, objective=qwk_obj_sii, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:32:14.288140Z","iopub.execute_input":"2025-01-20T05:32:14.288494Z","iopub.status.idle":"2025-01-20T05:32:14.293327Z","shell.execute_reply.started":"2025-01-20T05:32:14.288470Z","shell.execute_reply":"2025-01-20T05:32:14.292092Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"#xgb_model.fit(X_train_labelled, y_train_labelled)\n#xgb_model.fit(X_train_labelled, y_train_labelled_bin)\nxgb_model.fit(X_train_labelled, y_train_labelled_sii)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:32:19.695817Z","iopub.execute_input":"2025-01-20T05:32:19.696254Z","iopub.status.idle":"2025-01-20T05:32:20.112280Z","shell.execute_reply.started":"2025-01-20T05:32:19.696219Z","shell.execute_reply":"2025-01-20T05:32:20.111181Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None,\n             objective=<function qwk_obj_bin at 0x7a12261c2e60>, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None,\n             objective=&lt;function qwk_obj_bin at 0x7a12261c2e60&gt;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=5, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None,\n             objective=&lt;function qwk_obj_bin at 0x7a12261c2e60&gt;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":46},{"cell_type":"markdown","source":"Big improvement when using QWK as the objective function on the sii target: **0.420, 0.426** on the basic parameters. Did not get the same results from using QWK on the binned target or sii with NMSE. We cannot use QWK on the PCIAT-PCIAT_Total target, because we will have to bin them anyway, and the bins we used for the PCIAT_bin were already the most easily translatable to the final sii predictions (2:1). So going forward, we will use this objective + target when testing params.","metadata":{}},{"cell_type":"markdown","source":"# Final prediction with model","metadata":{}},{"cell_type":"code","source":"y_test = test_data[['id']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:34:16.941276Z","iopub.execute_input":"2025-01-20T05:34:16.941654Z","iopub.status.idle":"2025-01-20T05:34:16.947284Z","shell.execute_reply.started":"2025-01-20T05:34:16.941626Z","shell.execute_reply":"2025-01-20T05:34:16.946106Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"#y_test['PCIAT-PCIAT_Total_xgb'] = xgb_model.predict(X_test_fimpute)\n#y_test['PCIAT-PCIAT_Total_xgb'] = xgb_model.predict(X_test_fimpute_pca)\ny_test['PCIAT-PCIAT_Total_xgb'] = np.round(xgb_model.predict(X_test_fimpute))\ny_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:35:03.415423Z","iopub.execute_input":"2025-01-20T05:35:03.415774Z","iopub.status.idle":"2025-01-20T05:35:03.438377Z","shell.execute_reply.started":"2025-01-20T05:35:03.415744Z","shell.execute_reply":"2025-01-20T05:35:03.436118Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-49-b7ee60d2a15d>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  y_test['PCIAT-PCIAT_Total_xgb'] = np.round(xgb_model.predict(X_test_fimpute))\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"         id  PCIAT-PCIAT_Total_xgb\n0  00008ff9                    2.0\n1  000fd460                    1.0\n2  00105258                    2.0\n3  00115b9f                    1.0\n4  0016bb22                    2.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PCIAT-PCIAT_Total_xgb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"y_test['PCIAT-PCIAT_Total'] = y_test.apply(\n    lambda row: (row['PCIAT-PCIAT_Total_xgb']),\naxis=1)\n\n# Target PCIAT-PCIAT_Total\n#y_test['sii'] = y_test.apply(lambda row: 0 if row['PCIAT-PCIAT_Total']<=30 else \n#                             (1 if row['PCIAT-PCIAT_Total']<50 else (\n#                                2 if row['PCIAT-PCIAT_Total']<80 else (3)\n#                            )), axis=1)\n\n# Target bin\n#y_test['sii'] = y_test.apply(lambda row: 0 if row['PCIAT-PCIAT_Total']<2 else \n#                             (1 if row['PCIAT-PCIAT_Total']<4 else (\n#                                2 if row['PCIAT-PCIAT_Total']<6 else (3)\n#                            )), axis=1)\n\n# Target sii\ny_test['sii'] = y_test['PCIAT-PCIAT_Total_xgb']\n\ny_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:36:21.521012Z","iopub.execute_input":"2025-01-20T05:36:21.521373Z","iopub.status.idle":"2025-01-20T05:36:21.537427Z","shell.execute_reply.started":"2025-01-20T05:36:21.521348Z","shell.execute_reply":"2025-01-20T05:36:21.536178Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-50-0a0ffefd052f>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  y_test['PCIAT-PCIAT_Total'] = y_test.apply(\n<ipython-input-50-0a0ffefd052f>:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  y_test['sii'] = y_test.apply(lambda row: 0 if row['PCIAT-PCIAT_Total']<2 else\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"         id  PCIAT-PCIAT_Total_xgb  PCIAT-PCIAT_Total  sii\n0  00008ff9                    2.0                2.0    1\n1  000fd460                    1.0                1.0    0\n2  00105258                    2.0                2.0    1\n3  00115b9f                    1.0                1.0    0\n4  0016bb22                    2.0                2.0    1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PCIAT-PCIAT_Total_xgb</th>\n      <th>PCIAT-PCIAT_Total</th>\n      <th>sii</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"solution = y_test[['id','sii']]\nsolution.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:36:26.405724Z","iopub.execute_input":"2025-01-20T05:36:26.406112Z","iopub.status.idle":"2025-01-20T05:36:26.419217Z","shell.execute_reply.started":"2025-01-20T05:36:26.406082Z","shell.execute_reply":"2025-01-20T05:36:26.418035Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}